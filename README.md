# sagemaker-llm-finetuning-indic-languages
In this sagemaker example, we are going to fine-tune open LLM, zephyr-7b beta using QLoRA and how to deploy them afterwards using the Hugging Face LLM Inference DLC.
In our example, we are going to leverage Hugging Face Transformers, Accelerate, and PEFT. We will also make use of new and efficient features and methods including, Flash Attention,  and Mixed Precision Training.

what we are going to do:

1. Setup Development Environment
2. Load and prepare the dataset
3. Fine-Tune zephyr 7B with QLoRA on Amazon SageMaker
4. Deploy Fine-tuned zephyr 7B on Amazon SageMaker
5. Stream Inference Requests from the Deployed Model using aws lambda.

1. Setup Development Environment:
If you are going to use zephyr-7b you need to login into our hugging face account, to use your token for accessing the gated repository. We can do this by running the following command:

!huggingface-cli login --token YOUR_TOKEN

we are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker.

2. Load and prepare the dataset:-
We will use BB-Ultrachat-IndicLingual6-12k an open-source dataset, it is a curated dataset comprising 12,000 multi-turn conversations, which are a subset of the larger HuggingFaceH4/ultrachat_200k dataset from which zephyr-7b model is trained on. These conversations have been evenly distributed across six prominent Indic languages, namely English, Hindi, Tamil, Malayalam, Marathi, and Kannada.
The Indic language data in this dataset was generated by translating the chat data from the HuggingFaceH4/ultrachat_200k dataset using the advanced translation model IndicTrans2 by AI4Bharat.

now, to finetune our model we need to convert the dataset into an instruction format like converting the columns from the BB-Ultrachat-IndicLingual6-12k, messages into processed_text column. I have curated this processed_text column in a new dataset which is https://huggingface.co/datasets/piyushaaryan011/indic_bilingual. Where i have created a #text with the prompt and #response which is the response it should get.

3. Fine-Tune zephyr 7B with QLoRA on Amazon SageMaker:


