{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3044874-086f-4052-a5ba-1007be2b2da9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tranformers (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tranformers\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade sagemaker datasets tranformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad67afd-caba-4195-be85-3db06b120e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008ca166-22cb-43fe-8017-dcd532693f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c716e6a-7651-47d5-8680-b92fb8eb1083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::394697995665:role/service-role/AmazonSageMaker-ExecutionRole-20231221T174168\n",
      "sagemaker bucket: sagemaker-us-east-1-394697995665\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a200a069-092a-4c20-a3ce-5a5699e2cd61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "bi_dataset = load_dataset(\"piyushaaryan011/indic_bilingual\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd0ef73-b2de-4958-b884-202cd622d7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'processed_text'],\n",
       "    num_rows: 3229\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_and_test_bi_dataset = bi_dataset.train_test_split(test_size=0.1)\n",
    "bi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517a12a7-f088-43cf-aa1b-8da4d8078461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset= bi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02fbca1d-e527-4b5f-aead-17afd688dc28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# train_dataset, test_dataset = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3622be5-b204-4401-8966-dabdaa229e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = bi_dataset\n",
    "train_dataset = train_dataset.remove_columns([\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369d44de-ce87-4f27-a618-c042207d910e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['processed_text'],\n",
       "    num_rows: 3229\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bbdcc90-6696-469e-bb8d-7c327585f3fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset =  train_dataset.rename_column(\"processed_text\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5ec3fb-14ce-4db9-b4de-cb4fb9d46f54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '##text ग्राहक प्रतिक्रिया सर्वेक्षण बनाएँ और परिणामों का विश्लेषण करें ##response ग्राहक प्रतिक्रिया सर्वेक्षण 1. आप हमारे उत्पादों/सेवाओं से कितने संतुष्ट थे? (क) बहुत संतुष्ट (ख) संतुष्ट (ग) तटस्थ (घ) असंतुष्ट (ङ) बहुत असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतुष्ट (घ) असंतु आप दूसरों को हमारे उत्पादों/सेवाओं की सिफारिश करने की कितनी संभावना रखते हैं? ए) बहुत संभावना बी) संभावना सी) तटस्थ डी) संभावना ई) बहुत संभावना नहीं 3। हमारी ग्राहक सेवा टीम के साथ बातचीत करने का आपका अनुभव कैसा रहा? ए) उत्कृष्ट बी) अच्छा सी) औसत डी) गरीब ई) बहुत खराब 4। हमारी वेबसाइट को नेविगेट करना कितना आसान था? ए) बहुत आसान बी) आसान सी) तटस्थ डी) मुश्किल ई) बहुत मुश्किल 5। आप हमारे उत्पादों/सेवाओं को कितनी बार खरीदते हैं? a) दैनिक b) साप्ताहिक c) मासिक d) तिमाही e) शायद ही कभी 6। आपको हमारे उत्पादों/सेवाओं के बारे में सबसे ज्यादा क्या पसंद है? 7. आपको क्या लगता है कि हम क्या सुधार कर सकते हैं? 8. क्या आप हमारे उत्पादों/सेवाओं के साथ अपने अनुभव के बारे में कुछ और साझा करना चाहेंगे? परिणामों का विश्लेषण 100 प्रतिक्रिया प्रतिक्रियाओं में से अधिकांश (70 प्रतिशत) या तो हमारे उत्पादों/सेवाओं से बहुत संतुष्ट या संतुष्ट थे। 20 प्रतिशत तटस्थ थे और केवल 10 प्रतिशत असंतुष्ट या बहुत असंतुष्ट थे। यह इंगित करता है कि अधिकांश ग्राहक हमारे प्रस्तावों से खुश हैं। हमारे उत्पादों/सेवाओं की अनुशंसा करने की संभावना के बारे में पूछे जाने पर, 65 प्रतिशत ने कहा कि वे बहुत संभावना रखते हैं या अनुशंसा करने की संभावना रखते हैं, जबकि 25 प्रतिशत तटस्थ थे और 10 प्रतिशत की अनुशंसा करने की संभावना नहीं थी या बहुत संभावना नहीं थी। यह एक सकारात्मक प्रतिक्रिया है और इंगित करता है कि हमारे ग्राहक दूसरों को हमारी सिफारिश करने के लिए तैयार हैं। अधिकांश (60 प्रतिशत) ने हमारे ग्राहक सेवा दल के साथ बातचीत करने के अपने अनुभव को उत्कृष्ट या अच्छा बताया। 20 प्रतिशत ने इसे औसत के रूप में मूल्यांकन किया, जबकि 10 प्रतिशत ने इसे क्रमशः गरीब और बहुत गरीब के रूप में मूल्यांकन किया। यह एक अच्छी प्रतिक्रिया है, लेकिन हमें असंतुष्ट ग्राहकों के लिए ग्राहक सेवा अनुभव को बेहतर बनाने पर काम करने की आवश्यकता है। हमारी वेबसाइट को नेविगेट करने के बारे में पूछे जाने पर, 45 प्रतिशत ने कहा कि यह बहुत आसान या आसान था, जबकि 30 प्रतिशत तटस्थ थे और 25 प्रतिशत ने इसे मुश्किल या बहुत मुश्किल पाया। हमें इन ग्राहकों के लिए वेबसाइट अनुभव में सुधार करने की आवश्यकता है ताकि उनके लिए नेविगेट करना आसान हो सके। खरीद की आवृत्ति के संबंध में, 30 प्रतिशत ग्राहक हमारे उत्पादों/सेवाओं को मासिक रूप से खरीदते हैं, इसके बाद 25 प्रतिशत तिमाही खरीद करते हैं और 20 प्रतिशत साप्ताहिक खरीद करते हैं। 15 प्रतिशत शायद ही कभी खरीदते हैं और केवल 10 प्रतिशत दैनिक खरीद करते हैं। इससे हमें पता चलता है कि हमारे ग्राहक हमसे कितनी बार खरीदते हैं। हमारे उत्पादों/सेवाओं के बारे में ग्राहकों को सबसे अधिक क्या पसंद है, इसके बारे में अधिकांश (60 प्रतिशत) ने गुणवत्ता का उल्लेख किया, जबकि 20 प्रतिशत ने कीमत का उल्लेख किया और 10 प्रतिशत ने सुविधा का उल्लेख किया। इससे हमें यह समझने में मदद मिलती है कि ग्राहक हमारे प्रस्तावों के बारे में सबसे अधिक क्या महत्व देते हैं। जब उनसे पूछा गया कि हम किस पर सुधार कर सकते हैं, तो आम प्रतिक्रिया में ग्राहक सेवा, वेबसाइट नेविगेशन और मूल्य निर्धारण में सुधार शामिल था। हम बदलाव करते समय इस प्रतिक्रिया को ध्यान में रखेंगे। कुल मिलाकर, सर्वेक्षण के परिणाम इंगित करते हैं कि अधिकांश ग्राहक हमारे उत्पादों/सेवाओं से संतुष्ट हैं और दूसरों को हमारी सिफारिश करने की संभावना रखते हैं। हालांकि, वेबसाइट नेविगेशन और ग्राहक सेवा सहित कुछ क्षेत्रों में हमें सुधार करने की आवश्यकता है। हम अपने ग्राहकों को सर्वोत्तम अनुभव प्रदान करने के लिए आवश्यक परिवर्तन करने के लिए इस प्रतिक्रिया का उपयोग करेंगे। ##text ग्राहक प्रतिक्रिया सर्वेक्षण बनाने और परिणामों का विश्लेषण करने के लिए धन्यवाद। क्या आप कृपया इस बारे में अधिक जानकारी जोड़ सकते हैं कि हम ग्राहक प्रतिक्रिया के आधार पर अपने मूल्य निर्धारण में कैसे सुधार कर सकते हैं? ##response हां, ग्राहक प्रतिक्रिया सर्वेक्षण के परिणामों के आधार पर, 10 प्रतिशत ग्राहकों ने उल्लेख किया कि मूल्य निर्धारण एक ऐसा क्षेत्र है जिस पर हम सुधार कर सकते हैं। अपने मूल्य निर्धारण में सुधार करने के लिए, हम निम्नलिखित विकल्पों पर विचार कर सकते हैंः 1. शोध प्रतियोगी मूल्य निर्धारणः अपने प्रतियोगियों के मूल्य निर्धारण पर शोध करके, हम यह सुनिश्चित कर सकते हैं कि हमारी कीमतें प्रतिस्पर्धी हैं और उद्योग मानकों के अनुरूप हैं। हम प्रतियोगियों की कीमतों का विश्लेषण कर सकते हैं और उनकी तुलना अपनी कीमतों से कर सकते हैं ताकि यह सुनिश्चित किया जा सके कि हम अधिक शुल्क नहीं ले रहे हैं। 2. बंडल उत्पाद/सेवाएँः उत्पादों/सेवाओं को जोड़कर, हम ग्राहकों को छूट प्रदान कर सकते हैं, जिससे समग्र मूल्य अधिक आकर्षक हो जाता है। यह ग्राहकों को हमसे कई उत्पाद/सेवाएं खरीदने के लिए भी प्रोत्साहित कर सकता है। 3. प्रचार और छूट की पेशकशः नए और लौटने वाले ग्राहकों को विशेष प्रचार और छूट दी जा सकती है। यह ग्राहकों को हमारे साथ खरीदारी करने के लिए प्रोत्साहित कर सकता है। 4. एक वफादारी कार्यक्रम लागू करेंः एक वफादारी कार्यक्रम ग्राहकों को बार-बार खरीदारी करने के लिए प्रोत्साहित कर सकता है और उन्हें उनकी वफादारी के लिए पुरस्कृत कर सकता है। इसमें उन ग्राहकों के लिए छूट या विशेष प्रचार शामिल हो सकते हैं जो लगातार खरीदारी करते हैं। 5. गतिशील मूल्य निर्धारण लागू करेंः गतिशील मूल्य निर्धारण वास्तविक समय की मांग और आपूर्ति के आधार पर कीमतों को समायोजित करने का अभ्यास है। गतिशील मूल्य निर्धारण को लागू करके, हम यह सुनिश्चित कर सकते हैं कि हम बाजार की स्थितियों के आधार पर अपने उत्पादों/सेवाओं के लिए सही मूल्य वसूल रहे हैं। इन विकल्पों को लागू करके, हम अपने मूल्य निर्धारण में सुधार कर सकते हैं और अपने ग्राहकों की जरूरतों और अपेक्षाओं को बेहतर ढंग से पूरा कर सकते हैं। इसके अतिरिक्त, हम समय-समय पर चल रही ग्राहक प्रतिक्रिया और बाजार की स्थितियों के आधार पर अपनी मूल्य निर्धारण रणनीति की समीक्षा कर सकते हैं। ##text हम ग्राहकों की प्रतिक्रिया के आधार पर अपनी कीमतों में सुधार कैसे कर सकते हैं, इस पर दिए गए सुझावों के लिए धन्यवाद। क्या आप इस बारे में अधिक जानकारी प्रदान कर सकते हैं कि हम अपने उत्पादों/सेवाओं को ग्राहकों के लिए अधिक आकर्षक बनाने के लिए कैसे बना सकते हैं? ##response हां, उत्पादों और सेवाओं को जोड़ना ग्राहकों के लिए मूल्य निर्धारण को अधिक आकर्षक बनाने का एक शानदार तरीका है। यहाँ कुछ तरीके दिए गए हैं जिनसे हम अपनी पेशकशों को जोड़ सकते हैंः 1. बंडल से संबंधित उत्पाद/सेवाएँः दो या दो से अधिक संबंधित उत्पादों या सेवाओं को एक साथ जोड़ें। उदाहरण के लिए, हम एक लैपटॉप केस के साथ एक लैपटॉप या तेल के साथ एक कार वॉश बना सकते हैं। यह ग्राहकों को दोनों वस्तुओं को एक साथ खरीदने के लिए प्रोत्साहित कर सकता है और समग्र मूल्य को अधिक आकर्षक बना सकता है। 2. पूरक उत्पाद/सेवाएँः दो या दो से अधिक पूरक उत्पादों या सेवाओं को एक साथ जोड़ें। उदाहरण के लिए, हम स्याही के साथ एक प्रिंटर का बंडल बना सकते हैं या एक ब्लो-ड्राई के साथ बाल कटवा सकते हैं। यह ग्राहकों को एक बार में कई वस्तुओं को खरीदने के लिए प्रोत्साहित कर सकता है और समग्र मूल्य को अधिक आकर्षक बना सकता है। 3. पैकेज सौदे बनाएँः एक पैकेज सौदा बनाएँ जो छूट वाले मूल्य पर एक पैकेज में कई उत्पादों या सेवाओं को जोड़ता है। उदाहरण के लिए, हम एक फोन, लैपटॉप और हेडफ़ोन की एक जोड़ी को रियायती कीमत पर एक पैकेज में जोड़ सकते हैं। 4. मुफ्त परीक्षण या नमूना देंः किसी अन्य वस्तु की खरीद के साथ किसी उत्पाद या सेवा का निःशुल्क परीक्षण या नमूना दें। उदाहरण के लिए, हम एक लैपटॉप की खरीद के साथ एक सॉफ्टवेयर प्रोग्राम का मुफ्त परीक्षण प्रदान कर सकते हैं। यह ग्राहकों को हमारे उत्पादों/सेवाओं को आज़माने और भविष्य में खरीदारी करने के लिए प्रोत्साहित कर सकता है। 5. श्रेणीबद्ध मूल्य निर्धारण बनाएँः खरीदे गए उत्पादों या सेवाओं की संख्या के आधार पर श्रेणीबद्ध मूल्य निर्धारण की पेशकश करें। उदाहरण के लिए, हम उन ग्राहकों के लिए छूट की पेशकश कर सकते हैं जो एक बार में कई उत्पाद या सेवाएं खरीदते हैं। उत्पादों और सेवाओं को जोड़कर, हम ग्राहकों को उनके पैसे के लिए अधिक मूल्य प्रदान कर सकते हैं और समग्र खरीद को अधिक आकर्षक बना सकते हैं। यह ग्राहकों को समय और धन बचाने में मदद करता है और साथ ही उन्हें कई बार खरीदारी करने के लिए प्रोत्साहित करता है। </s>'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c562a087-a273-4dfd-bad7-a35718efc92e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3229/3229 [00:24<00:00, 129.56 examples/s]\n",
      "Map: 100%|██████████| 3229/3229 [00:28<00:00, 112.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 10340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "# # template dataset to add prompt to each sample\n",
    "# def template_dataset(sample):\n",
    "    # sample[\"text\"] = f\"{sample}{tokenizer.eos_token}\"\n",
    "    # return sample\n",
    "\n",
    "\n",
    "# # apply prompt template per sample\n",
    "# dataset = train_dataset.map(template_dataset, remove_columns=list(train_dataset.features))\n",
    "# # print random sample\n",
    "# print(dataset[randint(0, len(dataset))][\"text\"])\n",
    "\n",
    "# empty list to save remainder from batches to use in next batch\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}\n",
    "\n",
    "def chunk(sample, chunk_length=2048):\n",
    "    # print(f\"Chunking dataset into chunks of {chunk_length} tokens.\")\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "    # print(f\"Batch total length: {batch_total_length}\")\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "        # print(f\"Batch chunk length: {batch_chunk_length}\")\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "# tokenize and chunk dataset\n",
    "lm_dataset = train_dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(train_dataset.features)\n",
    ").map(\n",
    "    partial(chunk, chunk_length=2048),\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "# Print total number of samples\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d994301f-4a1d-4c77-8a81-a429159e4b10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-us-east-1-394697995665/zephyr4/indic/train\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/zephyr4/indic/train'\n",
    "# lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e678f88a-66f8-4266-8855-4e2a81a47d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'llm-sagemaker-sample' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/philschmid/llm-sagemaker-sample.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cce9045-387f-4f2f-a481-b15d32b7bd2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': 'HuggingFaceH4/zephyr-7b-beta',                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 1,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 4,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 1,                 # Number of updates steps to accumulate\n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'bf16': True,                                     # use bfloat16 precision\n",
    "  'tf32': True,                                     # use tf32 precision\n",
    "  'learning_rate': 2e-4,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"constant\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 20,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run',                         # output directory, where to save assets during training\n",
    "                                                    # could be used for checkpointing. The final trained\n",
    "                                                    # model will always be saved to s3 at the end of training\n",
    "}\n",
    " # huggingface token to access gated models, e.g. llama 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d77719ce-65ee-4e78-904f-a7f0b77ddc56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = 'llm-sagemaker-sample/scripts',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.2xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d28524-8f79-410f-bcbc-0f80babcc7f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-HuggingFaceH4-zephyr--2024-01-05-09-12-58-591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-05 09:12:59 Starting - Starting the training job...\n",
      "2024-01-05 09:13:14 Starting - Preparing the instances for training......\n",
      "2024-01-05 09:14:24 Downloading - Downloading input data...\n",
      "2024-01-05 09:14:59 Downloading - Downloading the training image..............................\n",
      "2024-01-05 09:20:00 Training - Training image download completed. Training in progress......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:36,799 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:36,818 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:36,827 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:36,828 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:38,169 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.34.0 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 90.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.4.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.4.0-py3-none-any.whl (72 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 21.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 43.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes==0.41.1 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 28.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 105.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 1)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.0->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 330.1/330.1 kB 57.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.15,>=0.14 (from transformers==4.34.0->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 112.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0->-r requirements.txt (line 1)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.0->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 295.0/295.0 kB 50.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: bitsandbytes, safetensors, huggingface-hub, tokenizers, accelerate, transformers, peft\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 bitsandbytes-0.41.1 huggingface-hub-0.17.3 peft-0.4.0 safetensors-0.4.1 tokenizers-0.14.1 transformers-4.34.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:49,905 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:49,905 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:49,946 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:49,973 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:50,001 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:50,011 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 1,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"logging_steps\": 20,\n",
      "        \"lr_scheduler_type\": \"constant\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"HuggingFaceH4/zephyr-7b-beta\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 4,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-HuggingFaceH4-zephyr--2024-01-05-09-12-58-591\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-394697995665/huggingface-qlora-HuggingFaceH4-zephyr--2024-01-05-09-12-58-591/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"learning_rate\":0.0002,\"logging_steps\":20,\"lr_scheduler_type\":\"constant\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"HuggingFaceH4/zephyr-7b-beta\",\"num_train_epochs\":1,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":4,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-394697995665/huggingface-qlora-HuggingFaceH4-zephyr--2024-01-05-09-12-58-591/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"learning_rate\":0.0002,\"logging_steps\":20,\"lr_scheduler_type\":\"constant\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"HuggingFaceH4/zephyr-7b-beta\",\"num_train_epochs\":1,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":4,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-HuggingFaceH4-zephyr--2024-01-05-09-12-58-591\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-394697995665/huggingface-qlora-HuggingFaceH4-zephyr--2024-01-05-09-12-58-591/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"1\",\"--gradient_checkpointing\",\"True\",\"--learning_rate\",\"0.0002\",\"--logging_steps\",\"20\",\"--lr_scheduler_type\",\"constant\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"HuggingFaceH4/zephyr-7b-beta\",\"--num_train_epochs\",\"1\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"4\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=1\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=constant\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=HuggingFaceH4/zephyr-7b-beta\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 1 --gradient_checkpointing True --learning_rate 0.0002 --logging_steps 20 --lr_scheduler_type constant --max_grad_norm 0.3 --merge_adapters True --model_id HuggingFaceH4/zephyr-7b-beta --num_train_epochs 1 --output_dir /tmp/run --per_device_train_batch_size 4 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-01-05 09:20:50,038 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.4.2.tar.gz (2.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 69.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.4.2-cp310-cp310-linux_x86_64.whl size=113930372 sha256=2c7ddc942e0715ef4a7ab62e3404b519a7ac040b3b6eae8fedcdc08a36ced786\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/9d/cf/7f/d14555553b5b30698dae0a4159fdd058157e7021cec565ecaa\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.4.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mDownloading config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading config.json: 100%|██████████| 638/638 [00:00<00:00, 6.40MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)fetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)fetensors.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 184MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   3%|▎         | 52.4M/1.89G [00:00<00:03, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   6%|▌         | 105M/1.89G [00:00<00:03, 473MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   8%|▊         | 157M/1.89G [00:00<00:03, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  11%|█         | 210M/1.89G [00:00<00:03, 484MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  14%|█▍        | 262M/1.89G [00:00<00:03, 480MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  17%|█▋        | 315M/1.89G [00:00<00:03, 479MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  19%|█▉        | 367M/1.89G [00:00<00:03, 481MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  22%|██▏       | 419M/1.89G [00:00<00:03, 483MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  25%|██▍       | 472M/1.89G [00:00<00:02, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  28%|██▊       | 524M/1.89G [00:01<00:02, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  31%|███       | 577M/1.89G [00:01<00:02, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  33%|███▎      | 629M/1.89G [00:01<00:02, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  36%|███▌      | 682M/1.89G [00:01<00:02, 493MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  39%|███▉      | 734M/1.89G [00:01<00:02, 494MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  42%|████▏     | 786M/1.89G [00:01<00:02, 494MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  44%|████▍     | 839M/1.89G [00:01<00:02, 493MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  47%|████▋     | 891M/1.89G [00:01<00:02, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  50%|████▉     | 944M/1.89G [00:01<00:01, 487MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  53%|█████▎    | 996M/1.89G [00:02<00:01, 487MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  55%|█████▌    | 1.05G/1.89G [00:02<00:01, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  58%|█████▊    | 1.10G/1.89G [00:02<00:01, 487MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  61%|██████    | 1.15G/1.89G [00:02<00:01, 485MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  64%|██████▍   | 1.21G/1.89G [00:02<00:01, 483MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  67%|██████▋   | 1.26G/1.89G [00:02<00:01, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  69%|██████▉   | 1.31G/1.89G [00:02<00:01, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  72%|███████▏  | 1.36G/1.89G [00:02<00:01, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  75%|███████▍  | 1.42G/1.89G [00:02<00:00, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  78%|███████▊  | 1.47G/1.89G [00:03<00:00, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  80%|████████  | 1.52G/1.89G [00:03<00:00, 493MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  83%|████████▎ | 1.57G/1.89G [00:03<00:00, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  86%|████████▌ | 1.63G/1.89G [00:03<00:00, 487MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  89%|████████▉ | 1.68G/1.89G [00:03<00:00, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  92%|█████████▏| 1.73G/1.89G [00:03<00:00, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  94%|█████████▍| 1.78G/1.89G [00:03<00:00, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  97%|█████████▋| 1.84G/1.89G [00:03<00:00, 481MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|█████████▉| 1.89G/1.89G [00:03<00:00, 487MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 1.89G/1.89G [00:03<00:00, 485MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  12%|█▎        | 1/8 [00:03<00:27,  3.98s/it]\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   3%|▎         | 52.4M/1.95G [00:00<00:03, 476MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   5%|▌         | 105M/1.95G [00:00<00:03, 488MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   8%|▊         | 157M/1.95G [00:00<00:03, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  11%|█         | 210M/1.95G [00:00<00:03, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  13%|█▎        | 262M/1.95G [00:00<00:03, 494MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  16%|█▌        | 315M/1.95G [00:00<00:03, 494MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  19%|█▉        | 367M/1.95G [00:00<00:03, 496MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  22%|██▏       | 419M/1.95G [00:00<00:03, 497MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  24%|██▍       | 472M/1.95G [00:00<00:02, 497MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  27%|██▋       | 524M/1.95G [00:01<00:02, 498MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  30%|██▉       | 577M/1.95G [00:01<00:02, 497MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  32%|███▏      | 629M/1.95G [00:01<00:02, 495MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  35%|███▌      | 682M/1.95G [00:01<00:02, 493MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  38%|███▊      | 734M/1.95G [00:01<00:02, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  40%|████      | 786M/1.95G [00:01<00:02, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  43%|████▎     | 839M/1.95G [00:01<00:02, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  46%|████▌     | 891M/1.95G [00:01<00:02, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  48%|████▊     | 944M/1.95G [00:01<00:02, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  51%|█████     | 996M/1.95G [00:02<00:01, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  54%|█████▍    | 1.05G/1.95G [00:02<00:01, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  57%|█████▋    | 1.10G/1.95G [00:02<00:01, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  59%|█████▉    | 1.15G/1.95G [00:02<00:01, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  62%|██████▏   | 1.21G/1.95G [00:02<00:01, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  65%|██████▍   | 1.26G/1.95G [00:02<00:01, 493MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  67%|██████▋   | 1.31G/1.95G [00:02<00:01, 493MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  70%|███████   | 1.36G/1.95G [00:02<00:01, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  73%|███████▎  | 1.42G/1.95G [00:02<00:01, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  75%|███████▌  | 1.47G/1.95G [00:03<00:01, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  78%|███████▊  | 1.52G/1.95G [00:03<00:00, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  81%|████████  | 1.57G/1.95G [00:03<00:00, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  84%|████████▎ | 1.63G/1.95G [00:03<00:00, 478MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  86%|████████▌ | 1.68G/1.95G [00:03<00:00, 480MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  89%|████████▉ | 1.73G/1.95G [00:03<00:00, 483MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  92%|█████████▏| 1.78G/1.95G [00:03<00:00, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  94%|█████████▍| 1.84G/1.95G [00:03<00:00, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  97%|█████████▋| 1.89G/1.95G [00:03<00:00, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|█████████▉| 1.94G/1.95G [00:03<00:00, 487MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 1.95G/1.95G [00:03<00:00, 487MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  25%|██▌       | 2/8 [00:08<00:24,  4.05s/it]\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   3%|▎         | 52.4M/1.98G [00:00<00:03, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   5%|▌         | 105M/1.98G [00:00<00:03, 485MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   8%|▊         | 157M/1.98G [00:00<00:03, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  11%|█         | 210M/1.98G [00:00<00:03, 476MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  13%|█▎        | 262M/1.98G [00:00<00:03, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  16%|█▌        | 315M/1.98G [00:00<00:03, 477MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  19%|█▊        | 367M/1.98G [00:00<00:03, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  21%|██        | 419M/1.98G [00:00<00:03, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  24%|██▍       | 472M/1.98G [00:00<00:03, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  26%|██▋       | 524M/1.98G [00:01<00:03, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  29%|██▉       | 577M/1.98G [00:01<00:02, 481MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  32%|███▏      | 629M/1.98G [00:01<00:02, 484MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  34%|███▍      | 682M/1.98G [00:01<00:02, 483MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  37%|███▋      | 734M/1.98G [00:01<00:02, 485MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  40%|███▉      | 786M/1.98G [00:01<00:02, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  42%|████▏     | 839M/1.98G [00:01<00:02, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  45%|████▌     | 891M/1.98G [00:01<00:02, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  48%|████▊     | 944M/1.98G [00:01<00:02, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  50%|█████     | 996M/1.98G [00:02<00:03, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  53%|█████▎    | 1.05G/1.98G [00:02<00:02, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  56%|█████▌    | 1.10G/1.98G [00:02<00:02, 383MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  58%|█████▊    | 1.15G/1.98G [00:02<00:02, 408MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  61%|██████    | 1.21G/1.98G [00:02<00:01, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  64%|██████▎   | 1.26G/1.98G [00:02<00:01, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  66%|██████▌   | 1.31G/1.98G [00:02<00:01, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  69%|██████▉   | 1.36G/1.98G [00:03<00:01, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  72%|███████▏  | 1.42G/1.98G [00:03<00:01, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  74%|███████▍  | 1.47G/1.98G [00:03<00:01, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  77%|███████▋  | 1.52G/1.98G [00:03<00:00, 477MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  79%|███████▉  | 1.57G/1.98G [00:03<00:00, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  82%|████████▏ | 1.63G/1.98G [00:03<00:00, 487MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  85%|████████▍ | 1.68G/1.98G [00:03<00:00, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  87%|████████▋ | 1.73G/1.98G [00:03<00:00, 484MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  90%|█████████ | 1.78G/1.98G [00:03<00:00, 483MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  93%|█████████▎| 1.84G/1.98G [00:03<00:00, 483MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  95%|█████████▌| 1.89G/1.98G [00:04<00:00, 484MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  98%|█████████▊| 1.94G/1.98G [00:04<00:00, 485MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 1.98G/1.98G [00:04<00:00, 461MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  38%|███▊      | 3/8 [00:12<00:20,  4.18s/it]\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   3%|▎         | 52.4M/1.95G [00:00<00:04, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   5%|▌         | 105M/1.95G [00:00<00:03, 474MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   8%|▊         | 157M/1.95G [00:00<00:03, 481MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  11%|█         | 210M/1.95G [00:00<00:03, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  13%|█▎        | 262M/1.95G [00:00<00:04, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  16%|█▌        | 304M/1.95G [00:00<00:05, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  18%|█▊        | 346M/1.95G [00:01<00:07, 226MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  19%|█▉        | 377M/1.95G [00:01<00:07, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  21%|██        | 409M/1.95G [00:01<00:07, 200MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  23%|██▎       | 440M/1.95G [00:01<00:08, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  24%|██▍       | 472M/1.95G [00:01<00:08, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  25%|██▌       | 493M/1.95G [00:02<00:08, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  26%|██▋       | 514M/1.95G [00:02<00:08, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  27%|██▋       | 535M/1.95G [00:02<00:08, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  29%|██▊       | 556M/1.95G [00:02<00:08, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  30%|██▉       | 577M/1.95G [00:02<00:07, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  31%|███       | 598M/1.95G [00:02<00:07, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  32%|███▏      | 629M/1.95G [00:02<00:07, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  34%|███▍      | 661M/1.95G [00:02<00:06, 195MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  35%|███▌      | 682M/1.95G [00:03<00:06, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  37%|███▋      | 713M/1.95G [00:03<00:06, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  38%|███▊      | 734M/1.95G [00:03<00:06, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  39%|███▉      | 765M/1.95G [00:03<00:05, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  41%|████      | 797M/1.95G [00:03<00:05, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  43%|████▎     | 828M/1.95G [00:03<00:05, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  44%|████▍     | 860M/1.95G [00:03<00:05, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  46%|████▌     | 891M/1.95G [00:04<00:05, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  47%|████▋     | 923M/1.95G [00:04<00:04, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  49%|████▉     | 954M/1.95G [00:04<00:04, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  51%|█████     | 986M/1.95G [00:04<00:04, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  52%|█████▏    | 1.01G/1.95G [00:04<00:04, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  53%|█████▎    | 1.04G/1.95G [00:04<00:04, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  55%|█████▍    | 1.07G/1.95G [00:04<00:04, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  56%|█████▌    | 1.09G/1.95G [00:05<00:04, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  57%|█████▋    | 1.11G/1.95G [00:05<00:04, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  58%|█████▊    | 1.13G/1.95G [00:05<00:03, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  60%|█████▉    | 1.16G/1.95G [00:05<00:03, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  61%|██████    | 1.18G/1.95G [00:05<00:03, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  62%|██████▏   | 1.21G/1.95G [00:05<00:03, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  64%|██████▎   | 1.24G/1.95G [00:05<00:03, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  65%|██████▍   | 1.26G/1.95G [00:05<00:03, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  66%|██████▌   | 1.28G/1.95G [00:05<00:03, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  67%|██████▋   | 1.30G/1.95G [00:06<00:03, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  68%|██████▊   | 1.33G/1.95G [00:06<00:02, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  70%|███████   | 1.36G/1.95G [00:06<00:02, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  72%|███████▏  | 1.39G/1.95G [00:06<00:02, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  73%|███████▎  | 1.42G/1.95G [00:06<00:02, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  74%|███████▍  | 1.45G/1.95G [00:06<00:02, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  76%|███████▌  | 1.48G/1.95G [00:06<00:02, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  78%|███████▊  | 1.51G/1.95G [00:07<00:02, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  79%|███████▉  | 1.54G/1.95G [00:07<00:01, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  80%|████████  | 1.56G/1.95G [00:07<00:01, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  82%|████████▏ | 1.59G/1.95G [00:07<00:01, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  84%|████████▎ | 1.63G/1.95G [00:07<00:01, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  85%|████████▌ | 1.66G/1.95G [00:07<00:01, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  86%|████████▌ | 1.68G/1.95G [00:08<00:01, 141MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  89%|████████▉ | 1.73G/1.95G [00:08<00:01, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  91%|█████████ | 1.77G/1.95G [00:08<00:00, 231MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  93%|█████████▎| 1.80G/1.95G [00:08<00:00, 221MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  94%|█████████▍| 1.84G/1.95G [00:08<00:00, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  96%|█████████▌| 1.87G/1.95G [00:08<00:00, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  98%|█████████▊| 1.90G/1.95G [00:08<00:00, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  99%|█████████▉| 1.93G/1.95G [00:09<00:00, 195MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 1.95G/1.95G [00:09<00:00, 209MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 4/8 [00:21<00:24,  6.24s/it]\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   2%|▏         | 41.9M/1.98G [00:00<00:05, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   4%|▍         | 83.9M/1.98G [00:00<00:07, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   6%|▌         | 115M/1.98G [00:00<00:08, 225MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   7%|▋         | 147M/1.98G [00:00<00:08, 212MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   9%|▉         | 178M/1.98G [00:00<00:09, 197MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  10%|█         | 199M/1.98G [00:00<00:08, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  11%|█         | 220M/1.98G [00:01<00:08, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  12%|█▏        | 241M/1.98G [00:01<00:08, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  13%|█▎        | 262M/1.98G [00:01<00:09, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  15%|█▍        | 294M/1.98G [00:01<00:08, 197MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  16%|█▌        | 315M/1.98G [00:01<00:08, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  17%|█▋        | 336M/1.98G [00:01<00:08, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  19%|█▊        | 367M/1.98G [00:01<00:08, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  20%|█▉        | 388M/1.98G [00:01<00:08, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  21%|██        | 409M/1.98G [00:02<00:08, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  22%|██▏       | 430M/1.98G [00:02<00:08, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  23%|██▎       | 451M/1.98G [00:02<00:08, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  24%|██▍       | 472M/1.98G [00:02<00:08, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  25%|██▍       | 493M/1.98G [00:02<00:08, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  26%|██▌       | 514M/1.98G [00:02<00:07, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  27%|██▋       | 535M/1.98G [00:02<00:07, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  28%|██▊       | 556M/1.98G [00:02<00:07, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  29%|██▉       | 577M/1.98G [00:02<00:07, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  30%|███       | 598M/1.98G [00:03<00:07, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  31%|███       | 619M/1.98G [00:03<00:07, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  32%|███▏      | 640M/1.98G [00:03<00:07, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  33%|███▎      | 661M/1.98G [00:03<00:07, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  34%|███▍      | 682M/1.98G [00:03<00:07, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  35%|███▌      | 703M/1.98G [00:03<00:07, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  37%|███▋      | 734M/1.98G [00:03<00:06, 187MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  38%|███▊      | 755M/1.98G [00:03<00:06, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  39%|███▉      | 776M/1.98G [00:04<00:06, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  41%|████      | 807M/1.98G [00:04<00:06, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  42%|████▏     | 828M/1.98G [00:04<00:06, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  43%|████▎     | 849M/1.98G [00:04<00:06, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  44%|████▍     | 870M/1.98G [00:04<00:05, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  45%|████▌     | 891M/1.98G [00:04<00:05, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  46%|████▌     | 912M/1.98G [00:04<00:06, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  47%|████▋     | 933M/1.98G [00:04<00:05, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  48%|████▊     | 954M/1.98G [00:05<00:06, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  49%|████▉     | 975M/1.98G [00:05<00:05, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  50%|█████     | 996M/1.98G [00:05<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  51%|█████▏    | 1.02G/1.98G [00:05<00:05, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  52%|█████▏    | 1.04G/1.98G [00:05<00:05, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  53%|█████▎    | 1.06G/1.98G [00:05<00:05, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  55%|█████▍    | 1.08G/1.98G [00:05<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  56%|█████▌    | 1.10G/1.98G [00:05<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  57%|█████▋    | 1.12G/1.98G [00:06<00:04, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  58%|█████▊    | 1.14G/1.98G [00:06<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  59%|█████▉    | 1.16G/1.98G [00:06<00:04, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  60%|█████▉    | 1.18G/1.98G [00:06<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  61%|██████    | 1.21G/1.98G [00:06<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  62%|██████▏   | 1.23G/1.98G [00:06<00:04, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  63%|██████▎   | 1.25G/1.98G [00:06<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  64%|██████▍   | 1.27G/1.98G [00:06<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  65%|██████▌   | 1.29G/1.98G [00:07<00:04, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  66%|██████▌   | 1.31G/1.98G [00:07<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  67%|██████▋   | 1.33G/1.98G [00:07<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  68%|██████▊   | 1.35G/1.98G [00:07<00:03, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  69%|██████▉   | 1.37G/1.98G [00:07<00:03, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  70%|███████   | 1.39G/1.98G [00:07<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  72%|███████▏  | 1.42G/1.98G [00:07<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  73%|███████▎  | 1.44G/1.98G [00:07<00:03, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  74%|███████▎  | 1.46G/1.98G [00:08<00:02, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  75%|███████▍  | 1.48G/1.98G [00:08<00:02, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  76%|███████▌  | 1.50G/1.98G [00:08<00:02, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  77%|███████▋  | 1.52G/1.98G [00:08<00:02, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  78%|███████▊  | 1.55G/1.98G [00:08<00:02, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  79%|███████▉  | 1.57G/1.98G [00:08<00:02, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  81%|████████  | 1.59G/1.98G [00:08<00:03, 125MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  83%|████████▎ | 1.65G/1.98G [00:09<00:01, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  85%|████████▍ | 1.68G/1.98G [00:09<00:01, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  86%|████████▋ | 1.71G/1.98G [00:09<00:01, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  87%|████████▋ | 1.73G/1.98G [00:09<00:01, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  88%|████████▊ | 1.75G/1.98G [00:09<00:01, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  90%|████████▉ | 1.77G/1.98G [00:09<00:01, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  91%|█████████ | 1.79G/1.98G [00:09<00:01, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  92%|█████████▏| 1.81G/1.98G [00:10<00:01, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  93%|█████████▎| 1.84G/1.98G [00:10<00:00, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  94%|█████████▎| 1.86G/1.98G [00:10<00:00, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  95%|█████████▍| 1.88G/1.98G [00:10<00:00, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  96%|█████████▌| 1.90G/1.98G [00:10<00:00, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  97%|█████████▋| 1.92G/1.98G [00:10<00:00, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  98%|█████████▊| 1.94G/1.98G [00:10<00:00, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  99%|█████████▉| 1.96G/1.98G [00:10<00:00, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 1.98G/1.98G [00:11<00:00, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 1.98G/1.98G [00:11<00:00, 178MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  62%|██████▎   | 5/8 [00:32<00:24,  8.02s/it]\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   2%|▏         | 31.5M/1.95G [00:00<00:07, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   3%|▎         | 62.9M/1.95G [00:00<00:09, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   4%|▍         | 83.9M/1.95G [00:00<00:09, 192MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   5%|▌         | 105M/1.95G [00:00<00:10, 174MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   6%|▋         | 126M/1.95G [00:00<00:10, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   8%|▊         | 147M/1.95G [00:00<00:10, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   9%|▊         | 168M/1.95G [00:00<00:10, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  10%|▉         | 189M/1.95G [00:01<00:10, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  11%|█         | 210M/1.95G [00:01<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  12%|█▏        | 231M/1.95G [00:01<00:09, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  13%|█▎        | 252M/1.95G [00:01<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  14%|█▍        | 273M/1.95G [00:01<00:09, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  15%|█▌        | 294M/1.95G [00:01<00:09, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  16%|█▌        | 315M/1.95G [00:01<00:09, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  17%|█▋        | 336M/1.95G [00:01<00:09, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  18%|█▊        | 357M/1.95G [00:01<00:08, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  20%|█▉        | 388M/1.95G [00:02<00:07, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  22%|██▏       | 419M/1.95G [00:02<00:06, 228MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  23%|██▎       | 451M/1.95G [00:02<00:06, 234MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  25%|██▍       | 482M/1.95G [00:02<00:06, 243MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  26%|██▋       | 514M/1.95G [00:02<00:05, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  28%|██▊       | 545M/1.95G [00:02<00:05, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  30%|██▉       | 577M/1.95G [00:02<00:05, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  31%|███       | 608M/1.95G [00:02<00:05, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  33%|███▎      | 640M/1.95G [00:03<00:04, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  34%|███▍      | 671M/1.95G [00:03<00:04, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  36%|███▌      | 703M/1.95G [00:03<00:04, 265MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  38%|███▊      | 734M/1.95G [00:03<00:04, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  39%|███▉      | 765M/1.95G [00:03<00:04, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  41%|████      | 797M/1.95G [00:03<00:04, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  43%|████▎     | 828M/1.95G [00:03<00:04, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  44%|████▍     | 860M/1.95G [00:03<00:04, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  46%|████▌     | 891M/1.95G [00:04<00:03, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  47%|████▋     | 923M/1.95G [00:04<00:03, 268MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  49%|████▉     | 954M/1.95G [00:04<00:03, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  51%|█████     | 986M/1.95G [00:04<00:03, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  52%|█████▏    | 1.02G/1.95G [00:04<00:03, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  54%|█████▍    | 1.05G/1.95G [00:04<00:03, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  55%|█████▌    | 1.08G/1.95G [00:04<00:03, 265MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  57%|█████▋    | 1.11G/1.95G [00:04<00:03, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  59%|█████▊    | 1.14G/1.95G [00:04<00:03, 254MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  60%|██████    | 1.17G/1.95G [00:05<00:03, 224MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  62%|██████▏   | 1.21G/1.95G [00:05<00:03, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  64%|██████▎   | 1.24G/1.95G [00:05<00:03, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  65%|██████▍   | 1.26G/1.95G [00:05<00:03, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  66%|██████▌   | 1.28G/1.95G [00:05<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  67%|██████▋   | 1.30G/1.95G [00:05<00:03, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  68%|██████▊   | 1.32G/1.95G [00:06<00:03, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  69%|██████▉   | 1.34G/1.95G [00:06<00:03, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  70%|███████   | 1.36G/1.95G [00:06<00:03, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  71%|███████   | 1.38G/1.95G [00:06<00:03, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  72%|███████▏  | 1.41G/1.95G [00:06<00:03, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  73%|███████▎  | 1.43G/1.95G [00:06<00:03, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  74%|███████▍  | 1.45G/1.95G [00:06<00:03, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  75%|███████▌  | 1.47G/1.95G [00:06<00:02, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  77%|███████▋  | 1.49G/1.95G [00:07<00:02, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  78%|███████▊  | 1.51G/1.95G [00:07<00:02, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  79%|███████▊  | 1.53G/1.95G [00:07<00:02, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  80%|███████▉  | 1.55G/1.95G [00:07<00:02, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  81%|████████  | 1.57G/1.95G [00:07<00:02, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  82%|████████▏ | 1.59G/1.95G [00:07<00:02, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  83%|████████▎ | 1.61G/1.95G [00:08<00:02, 121MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  86%|████████▌ | 1.67G/1.95G [00:08<00:01, 197MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  87%|████████▋ | 1.70G/1.95G [00:08<00:01, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  89%|████████▉ | 1.73G/1.95G [00:08<00:01, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  90%|████████▉ | 1.75G/1.95G [00:08<00:01, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  91%|█████████ | 1.77G/1.95G [00:08<00:01, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  92%|█████████▏| 1.79G/1.95G [00:08<00:00, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  93%|█████████▎| 1.81G/1.95G [00:09<00:00, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  94%|█████████▍| 1.84G/1.95G [00:09<00:00, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  95%|█████████▌| 1.86G/1.95G [00:09<00:00, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  96%|█████████▋| 1.88G/1.95G [00:09<00:00, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  98%|█████████▊| 1.90G/1.95G [00:09<00:00, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  99%|█████████▊| 1.92G/1.95G [00:09<00:00, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|█████████▉| 1.94G/1.95G [00:09<00:00, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 1.95G/1.95G [00:09<00:00, 195MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  75%|███████▌  | 6/8 [00:42<00:17,  8.69s/it]\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   2%|▏         | 31.5M/1.98G [00:00<00:06, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   3%|▎         | 62.9M/1.98G [00:00<00:09, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   5%|▍         | 94.4M/1.98G [00:00<00:10, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   6%|▌         | 115M/1.98G [00:00<00:10, 177MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   7%|▋         | 136M/1.98G [00:00<00:11, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   8%|▊         | 157M/1.98G [00:00<00:10, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   9%|▉         | 178M/1.98G [00:01<00:10, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  10%|█         | 199M/1.98G [00:01<00:10, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  11%|█         | 220M/1.98G [00:01<00:10, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  12%|█▏        | 241M/1.98G [00:01<00:10, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  13%|█▎        | 262M/1.98G [00:01<00:10, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  14%|█▍        | 283M/1.98G [00:01<00:10, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  15%|█▌        | 304M/1.98G [00:01<00:10, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  16%|█▋        | 325M/1.98G [00:01<00:10, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  17%|█▋        | 346M/1.98G [00:02<00:10, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  19%|█▊        | 367M/1.98G [00:02<00:09, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  20%|█▉        | 388M/1.98G [00:02<00:09, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  21%|██        | 409M/1.98G [00:02<00:09, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  22%|██▏       | 430M/1.98G [00:02<00:09, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  23%|██▎       | 451M/1.98G [00:02<00:09, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  24%|██▍       | 472M/1.98G [00:02<00:09, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  25%|██▍       | 493M/1.98G [00:02<00:09, 157MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  26%|██▌       | 514M/1.98G [00:03<00:09, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  27%|██▋       | 535M/1.98G [00:03<00:08, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  28%|██▊       | 556M/1.98G [00:03<00:08, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  29%|██▉       | 577M/1.98G [00:03<00:08, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  30%|███       | 598M/1.98G [00:03<00:08, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  31%|███       | 619M/1.98G [00:03<00:08, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  32%|███▏      | 640M/1.98G [00:03<00:08, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  33%|███▎      | 661M/1.98G [00:03<00:08, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  34%|███▍      | 682M/1.98G [00:04<00:08, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  35%|███▌      | 703M/1.98G [00:04<00:07, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  37%|███▋      | 724M/1.98G [00:04<00:07, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  38%|███▊      | 744M/1.98G [00:04<00:07, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  39%|███▊      | 765M/1.98G [00:04<00:07, 156MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  40%|███▉      | 786M/1.98G [00:04<00:07, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  41%|████      | 807M/1.98G [00:04<00:07, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  42%|████▏     | 828M/1.98G [00:05<00:07, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  43%|████▎     | 849M/1.98G [00:05<00:07, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  44%|████▍     | 870M/1.98G [00:05<00:06, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  45%|████▌     | 891M/1.98G [00:05<00:06, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  46%|████▌     | 912M/1.98G [00:05<00:06, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  47%|████▋     | 933M/1.98G [00:05<00:06, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  48%|████▊     | 954M/1.98G [00:05<00:06, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  49%|████▉     | 975M/1.98G [00:05<00:06, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  50%|█████     | 996M/1.98G [00:06<00:06, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  51%|█████▏    | 1.02G/1.98G [00:06<00:05, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  52%|█████▏    | 1.04G/1.98G [00:06<00:05, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  53%|█████▎    | 1.06G/1.98G [00:06<00:05, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  55%|█████▍    | 1.08G/1.98G [00:06<00:05, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  56%|█████▌    | 1.10G/1.98G [00:06<00:05, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  57%|█████▋    | 1.12G/1.98G [00:06<00:05, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  58%|█████▊    | 1.14G/1.98G [00:06<00:05, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  59%|█████▉    | 1.16G/1.98G [00:07<00:04, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  60%|█████▉    | 1.18G/1.98G [00:07<00:04, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  61%|██████    | 1.21G/1.98G [00:07<00:04, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  62%|██████▏   | 1.23G/1.98G [00:07<00:04, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  63%|██████▎   | 1.25G/1.98G [00:07<00:04, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  64%|██████▍   | 1.27G/1.98G [00:07<00:04, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  65%|██████▌   | 1.29G/1.98G [00:07<00:04, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  66%|██████▌   | 1.31G/1.98G [00:08<00:04, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  67%|██████▋   | 1.33G/1.98G [00:08<00:05, 120MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  70%|██████▉   | 1.38G/1.98G [00:08<00:03, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  72%|███████▏  | 1.42G/1.98G [00:08<00:03, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  73%|███████▎  | 1.45G/1.98G [00:08<00:03, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  74%|███████▍  | 1.47G/1.98G [00:08<00:03, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  75%|███████▌  | 1.49G/1.98G [00:09<00:03, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  76%|███████▋  | 1.51G/1.98G [00:09<00:02, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  77%|███████▋  | 1.53G/1.98G [00:09<00:02, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  78%|███████▊  | 1.55G/1.98G [00:09<00:02, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  79%|███████▉  | 1.57G/1.98G [00:09<00:02, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  81%|████████  | 1.59G/1.98G [00:09<00:02, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  82%|████████▏ | 1.61G/1.98G [00:09<00:02, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  83%|████████▎ | 1.64G/1.98G [00:10<00:02, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  84%|████████▎ | 1.66G/1.98G [00:10<00:01, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  85%|████████▍ | 1.68G/1.98G [00:10<00:01, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  86%|████████▌ | 1.70G/1.98G [00:10<00:01, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  87%|████████▋ | 1.72G/1.98G [00:10<00:01, 154MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  88%|████████▊ | 1.74G/1.98G [00:10<00:01, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  89%|████████▉ | 1.76G/1.98G [00:10<00:01, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  90%|█████████ | 1.78G/1.98G [00:10<00:01, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  91%|█████████ | 1.80G/1.98G [00:11<00:01, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  92%|█████████▏| 1.82G/1.98G [00:11<00:00, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  93%|█████████▎| 1.85G/1.98G [00:11<00:00, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  94%|█████████▍| 1.87G/1.98G [00:11<00:00, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  95%|█████████▌| 1.89G/1.98G [00:11<00:00, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  96%|█████████▋| 1.91G/1.98G [00:11<00:00, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  97%|█████████▋| 1.93G/1.98G [00:11<00:00, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  99%|█████████▊| 1.95G/1.98G [00:11<00:00, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|█████████▉| 1.97G/1.98G [00:12<00:00, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 1.98G/1.98G [00:12<00:00, 162MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  88%|████████▊ | 7/8 [00:55<00:09,  9.84s/it]\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   4%|▍         | 31.5M/816M [00:00<00:03, 250MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:   8%|▊         | 62.9M/816M [00:00<00:03, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  10%|█         | 83.9M/816M [00:00<00:04, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  13%|█▎        | 105M/816M [00:00<00:04, 167MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  15%|█▌        | 126M/816M [00:00<00:04, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  18%|█▊        | 147M/816M [00:00<00:04, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  21%|██        | 168M/816M [00:00<00:03, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  23%|██▎       | 189M/816M [00:01<00:03, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  26%|██▌       | 210M/816M [00:01<00:03, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  28%|██▊       | 231M/816M [00:01<00:03, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  31%|███       | 252M/816M [00:01<00:03, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  33%|███▎      | 273M/816M [00:01<00:03, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  36%|███▌      | 294M/816M [00:01<00:03, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  39%|███▊      | 315M/816M [00:01<00:03, 151MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  41%|████      | 336M/816M [00:02<00:03, 148MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  44%|████▎     | 357M/816M [00:02<00:03, 141MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  46%|████▋     | 377M/816M [00:02<00:03, 137MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  49%|████▉     | 398M/816M [00:02<00:03, 138MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  51%|█████▏    | 419M/816M [00:02<00:02, 136MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  54%|█████▍    | 440M/816M [00:02<00:02, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  57%|█████▋    | 461M/816M [00:03<00:02, 133MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  59%|█████▉    | 482M/816M [00:03<00:02, 132MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  62%|██████▏   | 503M/816M [00:03<00:02, 132MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  64%|██████▍   | 524M/816M [00:03<00:02, 131MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  67%|██████▋   | 545M/816M [00:03<00:02, 134MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  69%|██████▉   | 566M/816M [00:03<00:01, 144MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  72%|███████▏  | 587M/816M [00:03<00:01, 153MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  75%|███████▍  | 608M/816M [00:04<00:01, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  77%|███████▋  | 629M/816M [00:04<00:01, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  80%|███████▉  | 650M/816M [00:04<00:01, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  82%|████████▏ | 671M/816M [00:04<00:00, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  85%|████████▍ | 692M/816M [00:04<00:00, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  87%|████████▋ | 713M/816M [00:04<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  90%|████████▉ | 734M/816M [00:04<00:00, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  93%|█████████▎| 755M/816M [00:04<00:00, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  95%|█████████▌| 776M/816M [00:04<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors:  98%|█████████▊| 797M/816M [00:05<00:00, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 816M/816M [00:05<00:00, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading (…)of-00008.safetensors: 100%|██████████| 816M/816M [00:05<00:00, 155MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 8/8 [01:00<00:00,  8.39s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 8/8 [01:00<00:00,  7.56s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  12%|█▎        | 1/8 [00:04<00:28,  4.13s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 2/8 [00:10<00:31,  5.21s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  38%|███▊      | 3/8 [00:12<00:20,  4.00s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 4/8 [00:13<00:10,  2.68s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  62%|██████▎   | 5/8 [00:13<00:05,  1.95s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 6/8 [00:14<00:03,  1.51s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  88%|████████▊ | 7/8 [00:15<00:01,  1.23s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 8/8 [00:15<00:00,  1.06it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 8/8 [00:15<00:00,  1.95s/it]\u001b[0m\n",
      "\u001b[34mDownloading generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 1.29MB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['gate_proj', 'up_proj', 'down_proj', 'v_proj', 'q_proj', 'k_proj', 'o_proj']\u001b[0m\n",
      "\u001b[34mtrainable params: 167,772,160 || all params: 3,919,843,328 || trainable%: 4.280073103982997\u001b[0m\n",
      "\u001b[34m0%|          | 0/2585 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in float16.\u001b[0m\n",
      "\u001b[34m0%|          | 1/2585 [00:12<8:42:59, 12.14s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/2585 [00:23<8:34:38, 11.95s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/2585 [00:35<8:31:55, 11.90s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/2585 [00:47<8:30:39, 11.87s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 5/2585 [00:59<8:30:02, 11.86s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 6/2585 [01:11<8:29:33, 11.85s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 7/2585 [01:23<8:29:10, 11.85s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 8/2585 [01:34<8:28:52, 11.85s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 9/2585 [01:46<8:28:32, 11.84s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 10/2585 [01:58<8:28:17, 11.84s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 11/2585 [02:10<8:28:01, 11.84s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 12/2585 [02:22<8:27:40, 11.84s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 13/2585 [02:34<8:27:25, 11.84s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 14/2585 [02:46<8:27:11, 11.84s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 15/2585 [02:57<8:27:01, 11.84s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 16/2585 [03:09<8:26:46, 11.84s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 17/2585 [03:21<8:26:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 18/2585 [03:33<8:26:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 19/2585 [03:45<8:25:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 20/2585 [03:57<8:25:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9406, 'learning_rate': 0.0002, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m1%|          | 20/2585 [03:57<8:25:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 21/2585 [04:08<8:25:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 22/2585 [04:20<8:25:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 23/2585 [04:32<8:25:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 24/2585 [04:44<8:25:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 25/2585 [04:56<8:24:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 26/2585 [05:07<8:24:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 27/2585 [05:19<8:24:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 28/2585 [05:31<8:24:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 29/2585 [05:43<8:24:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 30/2585 [05:55<8:23:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 31/2585 [06:07<8:23:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 32/2585 [06:18<8:23:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 33/2585 [06:30<8:23:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 34/2585 [06:42<8:22:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 35/2585 [06:54<8:22:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 36/2585 [07:06<8:22:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 37/2585 [07:18<8:22:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 38/2585 [07:29<8:22:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 39/2585 [07:41<8:21:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 40/2585 [07:53<8:21:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9314, 'learning_rate': 0.0002, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m2%|▏         | 40/2585 [07:53<8:21:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 41/2585 [08:05<8:21:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 42/2585 [08:17<8:21:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 43/2585 [08:29<8:21:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 44/2585 [08:40<8:20:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 45/2585 [08:52<8:20:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 46/2585 [09:04<8:20:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 47/2585 [09:16<8:20:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 48/2585 [09:28<8:20:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 49/2585 [09:40<8:19:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 50/2585 [09:51<8:19:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 51/2585 [10:03<8:19:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 52/2585 [10:15<8:19:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 53/2585 [10:27<8:19:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 54/2585 [10:39<8:18:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 55/2585 [10:51<8:18:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 56/2585 [11:02<8:18:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 57/2585 [11:14<8:18:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 58/2585 [11:26<8:18:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 59/2585 [11:38<8:18:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 60/2585 [11:50<8:18:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8211, 'learning_rate': 0.0002, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m2%|▏         | 60/2585 [11:50<8:18:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 61/2585 [12:02<8:17:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 62/2585 [12:13<8:17:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 63/2585 [12:25<8:17:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 64/2585 [12:37<8:17:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 65/2585 [12:49<8:16:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 66/2585 [13:01<8:16:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 67/2585 [13:13<8:16:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 68/2585 [13:24<8:16:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 69/2585 [13:36<8:16:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 70/2585 [13:48<8:16:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 71/2585 [14:00<8:15:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 72/2585 [14:12<8:15:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 73/2585 [14:24<8:15:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 74/2585 [14:35<8:15:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 75/2585 [14:47<8:14:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 76/2585 [14:59<8:14:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 77/2585 [15:11<8:14:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 78/2585 [15:23<8:14:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 79/2585 [15:35<8:14:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 80/2585 [15:46<8:14:07, 11.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8015, 'learning_rate': 0.0002, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m3%|▎         | 80/2585 [15:46<8:14:07, 11.84s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 81/2585 [15:58<8:13:56, 11.84s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 82/2585 [16:10<8:13:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 83/2585 [16:22<8:13:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 84/2585 [16:34<8:13:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 85/2585 [16:46<8:12:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 86/2585 [16:57<8:12:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 87/2585 [17:09<8:12:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 88/2585 [17:21<8:12:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 89/2585 [17:33<8:12:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 90/2585 [17:45<8:12:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 91/2585 [17:57<8:11:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 92/2585 [18:08<8:11:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 93/2585 [18:20<8:11:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 94/2585 [18:32<8:11:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 95/2585 [18:44<8:11:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 96/2585 [18:56<8:10:59, 11.84s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 97/2585 [19:08<8:10:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 98/2585 [19:19<8:10:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 99/2585 [19:31<8:10:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 100/2585 [19:43<8:09:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.784, 'learning_rate': 0.0002, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m4%|▍         | 100/2585 [19:43<8:09:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 101/2585 [19:55<8:09:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 102/2585 [20:07<8:09:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 103/2585 [20:19<8:09:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 104/2585 [20:30<8:09:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 105/2585 [20:42<8:09:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 106/2585 [20:54<8:08:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 107/2585 [21:06<8:08:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 108/2585 [21:18<8:08:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 109/2585 [21:30<8:08:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 110/2585 [21:41<8:08:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 111/2585 [21:53<8:07:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 112/2585 [22:05<8:07:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 113/2585 [22:17<8:07:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 114/2585 [22:29<8:07:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 115/2585 [22:41<8:07:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 116/2585 [22:52<8:06:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 117/2585 [23:04<8:06:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 118/2585 [23:16<8:06:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 119/2585 [23:28<8:06:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 120/2585 [23:40<8:05:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7859, 'learning_rate': 0.0002, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34m5%|▍         | 120/2585 [23:40<8:05:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 121/2585 [23:51<8:05:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 122/2585 [24:03<8:05:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 123/2585 [24:15<8:05:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 124/2585 [24:27<8:04:57, 11.82s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 125/2585 [24:39<8:04:46, 11.82s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 126/2585 [24:51<8:04:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 127/2585 [25:02<8:04:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 128/2585 [25:14<8:04:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 129/2585 [25:26<8:04:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 130/2585 [25:38<8:03:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 131/2585 [25:50<8:03:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 132/2585 [26:02<8:03:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 133/2585 [26:13<8:03:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 134/2585 [26:25<8:03:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 135/2585 [26:37<8:03:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 136/2585 [26:49<8:03:06, 11.84s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 137/2585 [27:01<8:02:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 138/2585 [27:13<8:02:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 139/2585 [27:24<8:02:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 140/2585 [27:36<8:02:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7619, 'learning_rate': 0.0002, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34m5%|▌         | 140/2585 [27:36<8:02:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 141/2585 [27:48<8:02:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 142/2585 [28:00<8:01:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 143/2585 [28:12<8:01:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 144/2585 [28:24<8:01:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 145/2585 [28:35<8:01:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 146/2585 [28:47<8:00:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 147/2585 [28:59<8:00:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 148/2585 [29:11<8:00:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 149/2585 [29:23<8:00:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 150/2585 [29:35<8:00:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 151/2585 [29:46<7:59:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 152/2585 [29:58<7:59:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 153/2585 [30:10<7:59:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 154/2585 [30:22<7:59:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 155/2585 [30:34<7:59:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 156/2585 [30:46<7:58:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 157/2585 [30:57<7:58:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 158/2585 [31:09<7:58:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 159/2585 [31:21<7:58:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 160/2585 [31:33<7:58:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7136, 'learning_rate': 0.0002, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34m6%|▌         | 160/2585 [31:33<7:58:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 161/2585 [31:45<7:58:12, 11.84s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 162/2585 [31:57<7:58:02, 11.84s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 163/2585 [32:08<7:57:45, 11.84s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 164/2585 [32:20<7:57:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 165/2585 [32:32<7:57:23, 11.84s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 166/2585 [32:44<7:57:13, 11.84s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 167/2585 [32:56<7:57:01, 11.84s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 168/2585 [33:08<7:56:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 169/2585 [33:19<7:56:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 170/2585 [33:31<7:56:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 171/2585 [33:43<7:56:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 172/2585 [33:55<7:55:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 173/2585 [34:07<7:55:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 174/2585 [34:19<7:55:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 175/2585 [34:30<7:55:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 176/2585 [34:42<7:54:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 177/2585 [34:54<7:54:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 178/2585 [35:06<7:54:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 179/2585 [35:18<7:54:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 180/2585 [35:30<7:54:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7431, 'learning_rate': 0.0002, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34m7%|▋         | 180/2585 [35:30<7:54:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 181/2585 [35:41<7:54:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 182/2585 [35:53<7:53:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 183/2585 [36:05<7:53:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 184/2585 [36:17<7:53:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 185/2585 [36:29<7:53:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 186/2585 [36:40<7:52:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 187/2585 [36:52<7:52:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 188/2585 [37:04<7:52:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 189/2585 [37:16<7:52:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 190/2585 [37:28<7:52:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 191/2585 [37:40<7:51:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 192/2585 [37:51<7:51:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 193/2585 [38:03<7:51:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 194/2585 [38:15<7:51:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 195/2585 [38:27<7:51:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 196/2585 [38:39<7:50:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 197/2585 [38:51<7:50:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 198/2585 [39:02<7:50:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 199/2585 [39:14<7:50:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 200/2585 [39:26<7:50:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7511, 'learning_rate': 0.0002, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34m8%|▊         | 200/2585 [39:26<7:50:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 201/2585 [39:38<7:50:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 202/2585 [39:50<7:49:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 203/2585 [40:02<7:49:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 204/2585 [40:13<7:49:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 205/2585 [40:25<7:49:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 206/2585 [40:37<7:49:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 207/2585 [40:49<7:49:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 208/2585 [41:01<7:48:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 209/2585 [41:13<7:48:42, 11.84s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 210/2585 [41:24<7:48:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 211/2585 [41:36<7:48:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 212/2585 [41:48<7:47:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 213/2585 [42:00<7:47:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 214/2585 [42:12<7:47:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 215/2585 [42:24<7:47:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 216/2585 [42:35<7:47:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 217/2585 [42:47<7:46:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 218/2585 [42:59<7:46:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 219/2585 [43:11<7:46:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 220/2585 [43:23<7:46:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7185, 'learning_rate': 0.0002, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34m9%|▊         | 220/2585 [43:23<7:46:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 221/2585 [43:35<7:46:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 222/2585 [43:46<7:45:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 223/2585 [43:58<7:45:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 224/2585 [44:10<7:45:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 225/2585 [44:22<7:45:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 226/2585 [44:34<7:45:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 227/2585 [44:46<7:44:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 228/2585 [44:57<7:44:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 229/2585 [45:09<7:44:44, 11.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 230/2585 [45:21<7:44:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 231/2585 [45:33<7:44:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 232/2585 [45:45<7:44:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 233/2585 [45:57<7:43:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 234/2585 [46:08<7:43:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 235/2585 [46:20<7:43:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 236/2585 [46:32<7:43:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 237/2585 [46:44<7:43:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 238/2585 [46:56<7:42:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 239/2585 [47:08<7:42:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 240/2585 [47:19<7:42:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7305, 'learning_rate': 0.0002, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34m9%|▉         | 240/2585 [47:19<7:42:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 241/2585 [47:31<7:42:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 242/2585 [47:43<7:41:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 243/2585 [47:55<7:41:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 244/2585 [48:07<7:41:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 245/2585 [48:18<7:41:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 246/2585 [48:30<7:41:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 247/2585 [48:42<7:41:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 248/2585 [48:54<7:40:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 249/2585 [49:06<7:40:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 250/2585 [49:18<7:40:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 251/2585 [49:29<7:40:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 252/2585 [49:41<7:39:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 253/2585 [49:53<7:39:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 254/2585 [50:05<7:39:59, 11.84s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 255/2585 [50:17<7:39:57, 11.84s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 256/2585 [50:29<7:39:42, 11.84s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 257/2585 [50:41<7:39:21, 11.84s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 258/2585 [50:52<7:39:06, 11.84s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 259/2585 [51:04<7:38:48, 11.84s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 260/2585 [51:16<7:38:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7432, 'learning_rate': 0.0002, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34m10%|█         | 260/2585 [51:16<7:38:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 261/2585 [51:28<7:38:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 262/2585 [51:40<7:38:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 263/2585 [51:52<7:37:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 264/2585 [52:03<7:37:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 265/2585 [52:15<7:37:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 266/2585 [52:27<7:37:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 267/2585 [52:39<7:37:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 268/2585 [52:51<7:36:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 269/2585 [53:02<7:36:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 270/2585 [53:14<7:36:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 271/2585 [53:26<7:36:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 272/2585 [53:38<7:36:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 273/2585 [53:50<7:35:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 274/2585 [54:02<7:35:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 275/2585 [54:13<7:35:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 276/2585 [54:25<7:35:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 277/2585 [54:37<7:35:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 278/2585 [54:49<7:34:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 279/2585 [55:01<7:34:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 280/2585 [55:13<7:34:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7241, 'learning_rate': 0.0002, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34m11%|█         | 280/2585 [55:13<7:34:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 281/2585 [55:24<7:34:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 282/2585 [55:36<7:34:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 283/2585 [55:48<7:33:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 284/2585 [56:00<7:33:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 285/2585 [56:12<7:33:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 286/2585 [56:24<7:33:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 287/2585 [56:35<7:33:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 288/2585 [56:47<7:32:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 289/2585 [56:59<7:32:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 290/2585 [57:11<7:32:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 291/2585 [57:23<7:32:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 292/2585 [57:35<7:32:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 293/2585 [57:46<7:31:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 294/2585 [57:58<7:31:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 295/2585 [58:10<7:31:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 296/2585 [58:22<7:31:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 297/2585 [58:34<7:31:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 298/2585 [58:46<7:30:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 299/2585 [58:57<7:30:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 300/2585 [59:09<7:30:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6854, 'learning_rate': 0.0002, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 300/2585 [59:09<7:30:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 301/2585 [59:21<7:30:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 302/2585 [59:33<7:30:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 303/2585 [59:45<7:30:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 304/2585 [59:57<7:29:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 305/2585 [1:00:08<7:29:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 306/2585 [1:00:20<7:29:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 307/2585 [1:00:32<7:29:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 308/2585 [1:00:44<7:28:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 309/2585 [1:00:56<7:28:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 310/2585 [1:01:08<7:28:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 311/2585 [1:01:19<7:28:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 312/2585 [1:01:31<7:28:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 313/2585 [1:01:43<7:27:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 314/2585 [1:01:55<7:27:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 315/2585 [1:02:07<7:27:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 316/2585 [1:02:19<7:27:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 317/2585 [1:02:30<7:27:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 318/2585 [1:02:42<7:26:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 319/2585 [1:02:54<7:26:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 320/2585 [1:03:06<7:26:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6884, 'learning_rate': 0.0002, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 320/2585 [1:03:06<7:26:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 321/2585 [1:03:18<7:26:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 322/2585 [1:03:29<7:26:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 323/2585 [1:03:41<7:25:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 324/2585 [1:03:53<7:25:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 325/2585 [1:04:05<7:25:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 326/2585 [1:04:17<7:25:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 327/2585 [1:04:29<7:25:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 328/2585 [1:04:40<7:25:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 329/2585 [1:04:52<7:24:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 330/2585 [1:05:04<7:24:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 331/2585 [1:05:16<7:24:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 332/2585 [1:05:28<7:24:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 333/2585 [1:05:40<7:24:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 334/2585 [1:05:51<7:23:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 335/2585 [1:06:03<7:23:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 336/2585 [1:06:15<7:23:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 337/2585 [1:06:27<7:23:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 338/2585 [1:06:39<7:23:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 339/2585 [1:06:51<7:22:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 340/2585 [1:07:02<7:22:55, 11.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7345, 'learning_rate': 0.0002, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 340/2585 [1:07:02<7:22:55, 11.84s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 341/2585 [1:07:14<7:22:39, 11.84s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 342/2585 [1:07:26<7:22:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 343/2585 [1:07:38<7:22:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 344/2585 [1:07:50<7:21:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 345/2585 [1:08:02<7:21:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 346/2585 [1:08:13<7:21:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 347/2585 [1:08:25<7:21:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 348/2585 [1:08:37<7:20:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 349/2585 [1:08:49<7:20:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 350/2585 [1:09:01<7:20:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 351/2585 [1:09:13<7:20:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 352/2585 [1:09:24<7:20:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 353/2585 [1:09:36<7:20:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 354/2585 [1:09:48<7:19:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 355/2585 [1:10:00<7:19:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 356/2585 [1:10:12<7:19:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 357/2585 [1:10:24<7:19:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 358/2585 [1:10:35<7:19:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 359/2585 [1:10:47<7:19:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 360/2585 [1:10:59<7:18:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.706, 'learning_rate': 0.0002, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 360/2585 [1:10:59<7:18:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 361/2585 [1:11:11<7:18:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 362/2585 [1:11:23<7:18:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 363/2585 [1:11:35<7:18:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 364/2585 [1:11:46<7:18:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 365/2585 [1:11:58<7:17:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 366/2585 [1:12:10<7:17:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 367/2585 [1:12:22<7:17:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 368/2585 [1:12:34<7:17:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 369/2585 [1:12:46<7:17:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 370/2585 [1:12:57<7:16:55, 11.84s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 371/2585 [1:13:09<7:16:49, 11.84s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 372/2585 [1:13:21<7:16:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 373/2585 [1:13:33<7:16:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 374/2585 [1:13:45<7:15:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 375/2585 [1:13:57<7:15:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 376/2585 [1:14:08<7:15:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 377/2585 [1:14:20<7:15:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 378/2585 [1:14:32<7:15:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 379/2585 [1:14:44<7:14:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 380/2585 [1:14:56<7:14:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6296, 'learning_rate': 0.0002, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34m15%|█▍        | 380/2585 [1:14:56<7:14:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 381/2585 [1:15:08<7:14:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 382/2585 [1:15:19<7:14:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 383/2585 [1:15:31<7:14:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 384/2585 [1:15:43<7:13:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 385/2585 [1:15:55<7:13:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 386/2585 [1:16:07<7:13:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 387/2585 [1:16:19<7:13:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 388/2585 [1:16:30<7:13:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 389/2585 [1:16:42<7:13:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 390/2585 [1:16:54<7:12:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 391/2585 [1:17:06<7:12:46, 11.84s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 392/2585 [1:17:18<7:12:36, 11.84s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 393/2585 [1:17:30<7:12:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 394/2585 [1:17:41<7:12:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 395/2585 [1:17:53<7:12:06, 11.84s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 396/2585 [1:18:05<7:11:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 397/2585 [1:18:17<7:11:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 398/2585 [1:18:29<7:11:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 399/2585 [1:18:41<7:11:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 400/2585 [1:18:52<7:10:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7098, 'learning_rate': 0.0002, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 400/2585 [1:18:52<7:10:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 401/2585 [1:19:04<7:10:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 402/2585 [1:19:16<7:10:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 403/2585 [1:19:28<7:10:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 404/2585 [1:19:40<7:10:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 405/2585 [1:19:52<7:10:02, 11.84s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 406/2585 [1:20:03<7:09:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 407/2585 [1:20:15<7:09:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 408/2585 [1:20:27<7:09:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 409/2585 [1:20:39<7:09:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 410/2585 [1:20:51<7:08:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 411/2585 [1:21:03<7:08:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 412/2585 [1:21:14<7:08:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 413/2585 [1:21:26<7:08:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 414/2585 [1:21:38<7:08:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 415/2585 [1:21:50<7:07:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 416/2585 [1:22:02<7:07:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 417/2585 [1:22:13<7:07:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 418/2585 [1:22:25<7:07:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 419/2585 [1:22:37<7:06:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 420/2585 [1:22:49<7:06:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7139, 'learning_rate': 0.0002, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 420/2585 [1:22:49<7:06:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 421/2585 [1:23:01<7:06:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 422/2585 [1:23:13<7:06:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 423/2585 [1:23:24<7:06:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 424/2585 [1:23:36<7:06:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 425/2585 [1:23:48<7:05:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 426/2585 [1:24:00<7:05:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 427/2585 [1:24:12<7:05:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 428/2585 [1:24:24<7:05:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 429/2585 [1:24:35<7:05:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 430/2585 [1:24:47<7:04:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 431/2585 [1:24:59<7:04:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 432/2585 [1:25:11<7:04:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 433/2585 [1:25:23<7:04:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 434/2585 [1:25:35<7:04:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 435/2585 [1:25:46<7:03:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 436/2585 [1:25:58<7:03:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 437/2585 [1:26:10<7:03:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 438/2585 [1:26:22<7:03:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 439/2585 [1:26:34<7:03:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 440/2585 [1:26:46<7:02:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6623, 'learning_rate': 0.0002, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 440/2585 [1:26:46<7:02:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 441/2585 [1:26:57<7:02:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 442/2585 [1:27:09<7:02:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 443/2585 [1:27:21<7:02:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 444/2585 [1:27:33<7:02:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 445/2585 [1:27:45<7:01:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 446/2585 [1:27:57<7:01:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 447/2585 [1:28:08<7:01:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 448/2585 [1:28:20<7:01:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 449/2585 [1:28:32<7:01:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 450/2585 [1:28:44<7:00:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 451/2585 [1:28:56<7:00:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 452/2585 [1:29:08<7:00:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 453/2585 [1:29:19<7:00:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 454/2585 [1:29:31<7:00:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 455/2585 [1:29:43<6:59:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 456/2585 [1:29:55<6:59:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 457/2585 [1:30:07<6:59:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 458/2585 [1:30:19<6:59:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 459/2585 [1:30:30<6:59:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 460/2585 [1:30:42<6:59:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7041, 'learning_rate': 0.0002, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 460/2585 [1:30:42<6:59:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 461/2585 [1:30:54<6:58:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 462/2585 [1:31:06<6:58:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 463/2585 [1:31:18<6:58:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 464/2585 [1:31:30<6:58:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 465/2585 [1:31:41<6:57:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 466/2585 [1:31:53<6:57:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 467/2585 [1:32:05<6:57:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 468/2585 [1:32:17<6:57:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 469/2585 [1:32:29<6:57:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 470/2585 [1:32:41<6:57:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 471/2585 [1:32:52<6:56:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 472/2585 [1:33:04<6:56:47, 11.84s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 473/2585 [1:33:16<6:56:36, 11.84s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 474/2585 [1:33:28<6:56:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 475/2585 [1:33:40<6:56:15, 11.84s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 476/2585 [1:33:52<6:56:03, 11.84s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 477/2585 [1:34:03<6:55:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 478/2585 [1:34:15<6:55:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 479/2585 [1:34:27<6:55:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 480/2585 [1:34:39<6:55:13, 11.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.674, 'learning_rate': 0.0002, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m19%|█▊        | 480/2585 [1:34:39<6:55:13, 11.84s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 481/2585 [1:34:51<6:54:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 482/2585 [1:35:03<6:54:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 483/2585 [1:35:14<6:54:14, 11.82s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 484/2585 [1:35:26<6:54:03, 11.82s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 485/2585 [1:35:38<6:53:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 486/2585 [1:35:50<6:53:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 487/2585 [1:36:02<6:53:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 488/2585 [1:36:14<6:53:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 489/2585 [1:36:25<6:53:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 490/2585 [1:36:37<6:53:15, 11.84s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 491/2585 [1:36:49<6:53:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 492/2585 [1:37:01<6:52:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 493/2585 [1:37:13<6:52:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 494/2585 [1:37:25<6:52:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 495/2585 [1:37:36<6:52:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 496/2585 [1:37:48<6:51:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 497/2585 [1:38:00<6:51:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 498/2585 [1:38:12<6:51:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 499/2585 [1:38:24<6:51:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 500/2585 [1:38:35<6:51:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7628, 'learning_rate': 0.0002, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 500/2585 [1:38:35<6:51:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 501/2585 [1:38:47<6:50:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 502/2585 [1:38:59<6:50:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 503/2585 [1:39:11<6:50:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 504/2585 [1:39:23<6:50:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 505/2585 [1:39:35<6:50:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 506/2585 [1:39:46<6:50:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 507/2585 [1:39:58<6:49:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 508/2585 [1:40:10<6:49:41, 11.84s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 509/2585 [1:40:22<6:49:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 510/2585 [1:40:34<6:49:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 511/2585 [1:40:46<6:49:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 512/2585 [1:40:57<6:48:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 513/2585 [1:41:09<6:48:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 514/2585 [1:41:21<6:48:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 515/2585 [1:41:33<6:48:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 516/2585 [1:41:45<6:47:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 517/2585 [1:41:57<6:47:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 518/2585 [1:42:08<6:47:45, 11.84s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 519/2585 [1:42:20<6:47:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 520/2585 [1:42:32<6:47:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7156, 'learning_rate': 0.0002, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m20%|██        | 520/2585 [1:42:32<6:47:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 521/2585 [1:42:44<6:47:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 522/2585 [1:42:56<6:46:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 523/2585 [1:43:08<6:46:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 524/2585 [1:43:19<6:46:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 525/2585 [1:43:31<6:46:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 526/2585 [1:43:43<6:46:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 527/2585 [1:43:55<6:45:57, 11.84s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 528/2585 [1:44:07<6:45:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 529/2585 [1:44:19<6:45:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 530/2585 [1:44:30<6:45:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 531/2585 [1:44:42<6:45:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 532/2585 [1:44:54<6:44:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 533/2585 [1:45:06<6:44:45, 11.84s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 534/2585 [1:45:18<6:44:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 535/2585 [1:45:30<6:44:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 536/2585 [1:45:41<6:44:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 537/2585 [1:45:53<6:43:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 538/2585 [1:46:05<6:43:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 539/2585 [1:46:17<6:43:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 540/2585 [1:46:29<6:43:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6554, 'learning_rate': 0.0002, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34m21%|██        | 540/2585 [1:46:29<6:43:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 541/2585 [1:46:41<6:42:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 542/2585 [1:46:52<6:42:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 543/2585 [1:47:04<6:42:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 544/2585 [1:47:16<6:42:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 545/2585 [1:47:28<6:42:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 546/2585 [1:47:40<6:42:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 547/2585 [1:47:52<6:41:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 548/2585 [1:48:03<6:41:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 549/2585 [1:48:15<6:41:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 550/2585 [1:48:27<6:41:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 551/2585 [1:48:39<6:41:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 552/2585 [1:48:51<6:40:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 553/2585 [1:49:03<6:40:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 554/2585 [1:49:14<6:40:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 555/2585 [1:49:26<6:40:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 556/2585 [1:49:38<6:40:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 557/2585 [1:49:50<6:39:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 558/2585 [1:50:02<6:39:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 559/2585 [1:50:14<6:39:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 560/2585 [1:50:25<6:39:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6991, 'learning_rate': 0.0002, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 560/2585 [1:50:25<6:39:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 561/2585 [1:50:37<6:39:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 562/2585 [1:50:49<6:38:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 563/2585 [1:51:01<6:38:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 564/2585 [1:51:13<6:38:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 565/2585 [1:51:25<6:38:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 566/2585 [1:51:36<6:38:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 567/2585 [1:51:48<6:37:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 568/2585 [1:52:00<6:37:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 569/2585 [1:52:12<6:37:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 570/2585 [1:52:24<6:37:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 571/2585 [1:52:35<6:37:16, 11.84s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 572/2585 [1:52:47<6:36:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 573/2585 [1:52:59<6:36:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 574/2585 [1:53:11<6:36:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 575/2585 [1:53:23<6:36:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 576/2585 [1:53:35<6:36:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 577/2585 [1:53:46<6:36:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 578/2585 [1:53:58<6:35:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 579/2585 [1:54:10<6:35:41, 11.84s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 580/2585 [1:54:22<6:35:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6411, 'learning_rate': 0.0002, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 580/2585 [1:54:22<6:35:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 581/2585 [1:54:34<6:35:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 582/2585 [1:54:46<6:34:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 583/2585 [1:54:57<6:34:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 584/2585 [1:55:09<6:34:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 585/2585 [1:55:21<6:34:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 586/2585 [1:55:33<6:34:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 587/2585 [1:55:45<6:33:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 588/2585 [1:55:57<6:33:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 589/2585 [1:56:08<6:33:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 590/2585 [1:56:20<6:33:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 591/2585 [1:56:32<6:33:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 592/2585 [1:56:44<6:32:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 593/2585 [1:56:56<6:32:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 594/2585 [1:57:08<6:32:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 595/2585 [1:57:19<6:32:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 596/2585 [1:57:31<6:32:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 597/2585 [1:57:43<6:31:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 598/2585 [1:57:55<6:31:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 599/2585 [1:58:07<6:31:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 600/2585 [1:58:19<6:31:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6816, 'learning_rate': 0.0002, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 600/2585 [1:58:19<6:31:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 601/2585 [1:58:30<6:31:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 602/2585 [1:58:42<6:30:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 603/2585 [1:58:54<6:30:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 604/2585 [1:59:06<6:30:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 605/2585 [1:59:18<6:30:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 606/2585 [1:59:30<6:30:21, 11.84s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 607/2585 [1:59:41<6:30:13, 11.84s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 608/2585 [1:59:53<6:29:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 609/2585 [2:00:05<6:29:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 610/2585 [2:00:17<6:29:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 611/2585 [2:00:29<6:29:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 612/2585 [2:00:41<6:29:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 613/2585 [2:00:52<6:28:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 614/2585 [2:01:04<6:28:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 615/2585 [2:01:16<6:28:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 616/2585 [2:01:28<6:28:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 617/2585 [2:01:40<6:27:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 618/2585 [2:01:52<6:27:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 619/2585 [2:02:03<6:27:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 620/2585 [2:02:15<6:27:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.669, 'learning_rate': 0.0002, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 620/2585 [2:02:15<6:27:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 621/2585 [2:02:27<6:27:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 622/2585 [2:02:39<6:27:12, 11.84s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 623/2585 [2:02:51<6:26:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 624/2585 [2:03:03<6:26:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 625/2585 [2:03:14<6:26:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 626/2585 [2:03:26<6:26:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 627/2585 [2:03:38<6:26:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 628/2585 [2:03:50<6:25:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 629/2585 [2:04:02<6:25:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 630/2585 [2:04:14<6:25:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 631/2585 [2:04:25<6:25:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 632/2585 [2:04:37<6:25:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 633/2585 [2:04:49<6:24:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 634/2585 [2:05:01<6:24:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 635/2585 [2:05:13<6:24:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 636/2585 [2:05:25<6:24:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 637/2585 [2:05:36<6:24:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 638/2585 [2:05:48<6:23:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 639/2585 [2:06:00<6:23:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 640/2585 [2:06:12<6:23:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6433, 'learning_rate': 0.0002, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34m25%|██▍       | 640/2585 [2:06:12<6:23:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 641/2585 [2:06:24<6:23:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 642/2585 [2:06:36<6:23:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 643/2585 [2:06:47<6:22:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 644/2585 [2:06:59<6:22:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 645/2585 [2:07:11<6:22:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 646/2585 [2:07:23<6:22:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 647/2585 [2:07:35<6:22:18, 11.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 648/2585 [2:07:47<6:22:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 649/2585 [2:07:58<6:21:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 650/2585 [2:08:10<6:21:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 651/2585 [2:08:22<6:21:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 652/2585 [2:08:34<6:21:21, 11.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 653/2585 [2:08:46<6:21:08, 11.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 654/2585 [2:08:58<6:20:56, 11.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 655/2585 [2:09:09<6:20:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 656/2585 [2:09:21<6:20:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 657/2585 [2:09:33<6:20:18, 11.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 658/2585 [2:09:45<6:20:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 659/2585 [2:09:57<6:19:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 660/2585 [2:10:09<6:19:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6177, 'learning_rate': 0.0002, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 660/2585 [2:10:09<6:19:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 661/2585 [2:10:20<6:19:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 662/2585 [2:10:32<6:19:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 663/2585 [2:10:44<6:19:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 664/2585 [2:10:56<6:18:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 665/2585 [2:11:08<6:18:44, 11.84s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 666/2585 [2:11:20<6:18:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 667/2585 [2:11:31<6:18:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 668/2585 [2:11:43<6:18:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 669/2585 [2:11:55<6:17:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 670/2585 [2:12:07<6:17:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 671/2585 [2:12:19<6:17:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 672/2585 [2:12:30<6:17:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 673/2585 [2:12:42<6:17:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 674/2585 [2:12:54<6:16:58, 11.84s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 675/2585 [2:13:06<6:16:46, 11.84s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 676/2585 [2:13:18<6:16:35, 11.84s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 677/2585 [2:13:30<6:16:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 678/2585 [2:13:41<6:16:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 679/2585 [2:13:53<6:15:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 680/2585 [2:14:05<6:15:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6422, 'learning_rate': 0.0002, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34m26%|██▋       | 680/2585 [2:14:05<6:15:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 681/2585 [2:14:17<6:15:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 682/2585 [2:14:29<6:15:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 683/2585 [2:14:41<6:14:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 684/2585 [2:14:52<6:14:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 685/2585 [2:15:04<6:14:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 686/2585 [2:15:16<6:14:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 687/2585 [2:15:28<6:14:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 688/2585 [2:15:40<6:13:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 689/2585 [2:15:52<6:13:40, 11.82s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 690/2585 [2:16:03<6:13:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 691/2585 [2:16:15<6:13:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 692/2585 [2:16:27<6:13:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 693/2585 [2:16:39<6:13:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 694/2585 [2:16:51<6:12:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 695/2585 [2:17:03<6:12:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 696/2585 [2:17:14<6:12:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 697/2585 [2:17:26<6:12:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 698/2585 [2:17:38<6:12:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 699/2585 [2:17:50<6:11:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 700/2585 [2:18:02<6:11:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6574, 'learning_rate': 0.0002, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 700/2585 [2:18:02<6:11:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 701/2585 [2:18:14<6:11:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 702/2585 [2:18:25<6:11:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 703/2585 [2:18:37<6:11:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 704/2585 [2:18:49<6:10:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 705/2585 [2:19:01<6:10:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 706/2585 [2:19:13<6:10:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 707/2585 [2:19:25<6:10:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 708/2585 [2:19:36<6:10:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 709/2585 [2:19:48<6:09:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 710/2585 [2:20:00<6:09:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 711/2585 [2:20:12<6:09:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 712/2585 [2:20:24<6:09:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 713/2585 [2:20:36<6:09:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 714/2585 [2:20:47<6:08:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 715/2585 [2:20:59<6:08:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 716/2585 [2:21:11<6:08:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 717/2585 [2:21:23<6:08:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 718/2585 [2:21:35<6:08:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 719/2585 [2:21:47<6:07:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 720/2585 [2:21:58<6:07:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.671, 'learning_rate': 0.0002, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 720/2585 [2:21:58<6:07:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 721/2585 [2:22:10<6:07:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 722/2585 [2:22:22<6:07:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 723/2585 [2:22:34<6:07:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 724/2585 [2:22:46<6:06:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 725/2585 [2:22:57<6:06:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 726/2585 [2:23:09<6:06:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 727/2585 [2:23:21<6:06:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 728/2585 [2:23:33<6:06:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 729/2585 [2:23:45<6:06:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 730/2585 [2:23:57<6:06:45, 11.86s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 731/2585 [2:24:09<6:06:12, 11.85s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 732/2585 [2:24:20<6:05:53, 11.85s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 733/2585 [2:24:32<6:05:32, 11.84s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 734/2585 [2:24:44<6:05:08, 11.84s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 735/2585 [2:24:56<6:04:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 736/2585 [2:25:08<6:04:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 737/2585 [2:25:20<6:04:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 738/2585 [2:25:31<6:04:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 739/2585 [2:25:43<6:03:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 740/2585 [2:25:55<6:03:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6235, 'learning_rate': 0.0002, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m29%|██▊       | 740/2585 [2:25:55<6:03:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 741/2585 [2:26:07<6:03:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 742/2585 [2:26:19<6:03:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 743/2585 [2:26:31<6:03:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 744/2585 [2:26:42<6:02:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 745/2585 [2:26:54<6:02:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 746/2585 [2:27:06<6:02:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 747/2585 [2:27:18<6:02:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 748/2585 [2:27:30<6:02:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 749/2585 [2:27:42<6:02:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 750/2585 [2:27:53<6:01:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 751/2585 [2:28:05<6:01:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 752/2585 [2:28:17<6:01:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 753/2585 [2:28:29<6:01:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 754/2585 [2:28:41<6:01:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 755/2585 [2:28:52<6:00:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 756/2585 [2:29:04<6:00:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 757/2585 [2:29:16<6:00:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 758/2585 [2:29:28<6:00:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 759/2585 [2:29:40<6:00:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 760/2585 [2:29:52<5:59:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6767, 'learning_rate': 0.0002, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 760/2585 [2:29:52<5:59:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 761/2585 [2:30:04<5:59:49, 11.84s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 762/2585 [2:30:15<5:59:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 763/2585 [2:30:27<5:59:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 764/2585 [2:30:39<5:59:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 765/2585 [2:30:51<5:58:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 766/2585 [2:31:03<5:58:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 767/2585 [2:31:14<5:58:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 768/2585 [2:31:26<5:58:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 769/2585 [2:31:38<5:58:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 770/2585 [2:31:50<5:57:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 771/2585 [2:32:02<5:57:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 772/2585 [2:32:14<5:57:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 773/2585 [2:32:25<5:57:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 774/2585 [2:32:37<5:57:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 775/2585 [2:32:49<5:56:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 776/2585 [2:33:01<5:56:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 777/2585 [2:33:13<5:56:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 778/2585 [2:33:25<5:56:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 779/2585 [2:33:36<5:56:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 780/2585 [2:33:48<5:55:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7715, 'learning_rate': 0.0002, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34m30%|███       | 780/2585 [2:33:48<5:55:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 781/2585 [2:34:00<5:55:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 782/2585 [2:34:12<5:55:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 783/2585 [2:34:24<5:55:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 784/2585 [2:34:36<5:55:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 785/2585 [2:34:47<5:55:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 786/2585 [2:34:59<5:54:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 787/2585 [2:35:11<5:54:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 788/2585 [2:35:23<5:54:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 789/2585 [2:35:35<5:54:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 790/2585 [2:35:47<5:53:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 791/2585 [2:35:58<5:53:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 792/2585 [2:36:10<5:53:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 793/2585 [2:36:22<5:53:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 794/2585 [2:36:34<5:53:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 795/2585 [2:36:46<5:53:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 796/2585 [2:36:58<5:52:53, 11.84s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 797/2585 [2:37:09<5:52:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 798/2585 [2:37:21<5:52:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 799/2585 [2:37:33<5:52:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 800/2585 [2:37:45<5:51:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6357, 'learning_rate': 0.0002, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34m31%|███       | 800/2585 [2:37:45<5:51:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 801/2585 [2:37:57<5:51:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 802/2585 [2:38:09<5:51:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 803/2585 [2:38:20<5:51:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 804/2585 [2:38:32<5:51:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 805/2585 [2:38:44<5:50:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 806/2585 [2:38:56<5:50:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 807/2585 [2:39:08<5:50:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 808/2585 [2:39:20<5:50:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 809/2585 [2:39:31<5:50:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 810/2585 [2:39:43<5:50:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 811/2585 [2:39:55<5:49:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 812/2585 [2:40:07<5:49:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 813/2585 [2:40:19<5:49:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 814/2585 [2:40:31<5:49:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 815/2585 [2:40:42<5:49:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 816/2585 [2:40:54<5:48:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 817/2585 [2:41:06<5:48:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 818/2585 [2:41:18<5:48:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 819/2585 [2:41:30<5:48:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 820/2585 [2:41:42<5:47:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6321, 'learning_rate': 0.0002, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 820/2585 [2:41:42<5:47:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 821/2585 [2:41:53<5:47:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 822/2585 [2:42:05<5:47:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 823/2585 [2:42:17<5:47:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 824/2585 [2:42:29<5:47:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 825/2585 [2:42:41<5:47:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 826/2585 [2:42:53<5:46:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 827/2585 [2:43:04<5:46:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 828/2585 [2:43:16<5:46:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 829/2585 [2:43:28<5:46:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 830/2585 [2:43:40<5:46:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 831/2585 [2:43:52<5:45:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 832/2585 [2:44:04<5:45:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 833/2585 [2:44:15<5:45:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 834/2585 [2:44:27<5:45:05, 11.82s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 835/2585 [2:44:39<5:44:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 836/2585 [2:44:51<5:44:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 837/2585 [2:45:03<5:44:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 838/2585 [2:45:14<5:44:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 839/2585 [2:45:26<5:44:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 840/2585 [2:45:38<5:44:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6094, 'learning_rate': 0.0002, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 840/2585 [2:45:38<5:44:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 841/2585 [2:45:50<5:43:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 842/2585 [2:46:02<5:43:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 843/2585 [2:46:14<5:43:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 844/2585 [2:46:25<5:43:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 845/2585 [2:46:37<5:43:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 846/2585 [2:46:49<5:43:03, 11.84s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 847/2585 [2:47:01<5:42:50, 11.84s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 848/2585 [2:47:13<5:42:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 849/2585 [2:47:25<5:42:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 850/2585 [2:47:36<5:42:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 851/2585 [2:47:48<5:41:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 852/2585 [2:48:00<5:41:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 853/2585 [2:48:12<5:41:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 854/2585 [2:48:24<5:41:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 855/2585 [2:48:36<5:41:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 856/2585 [2:48:47<5:40:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 857/2585 [2:48:59<5:40:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 858/2585 [2:49:11<5:40:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 859/2585 [2:49:23<5:40:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 860/2585 [2:49:35<5:40:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5836, 'learning_rate': 0.0002, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 860/2585 [2:49:35<5:40:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 861/2585 [2:49:47<5:39:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 862/2585 [2:49:58<5:39:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 863/2585 [2:50:10<5:39:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 864/2585 [2:50:22<5:39:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 865/2585 [2:50:34<5:39:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 866/2585 [2:50:46<5:39:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 867/2585 [2:50:58<5:38:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 868/2585 [2:51:09<5:38:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 869/2585 [2:51:21<5:38:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 870/2585 [2:51:33<5:38:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 871/2585 [2:51:45<5:37:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 872/2585 [2:51:57<5:37:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 873/2585 [2:52:09<5:37:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 874/2585 [2:52:20<5:37:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 875/2585 [2:52:32<5:37:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 876/2585 [2:52:44<5:36:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 877/2585 [2:52:56<5:36:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 878/2585 [2:53:08<5:36:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 879/2585 [2:53:20<5:36:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 880/2585 [2:53:31<5:36:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6365, 'learning_rate': 0.0002, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 880/2585 [2:53:31<5:36:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 881/2585 [2:53:43<5:36:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 882/2585 [2:53:55<5:35:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 883/2585 [2:54:07<5:35:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 884/2585 [2:54:19<5:35:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 885/2585 [2:54:31<5:35:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 886/2585 [2:54:42<5:34:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 887/2585 [2:54:54<5:34:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 888/2585 [2:55:06<5:34:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 889/2585 [2:55:18<5:34:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 890/2585 [2:55:30<5:34:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 891/2585 [2:55:42<5:34:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 892/2585 [2:55:53<5:33:56, 11.84s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 893/2585 [2:56:05<5:33:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 894/2585 [2:56:17<5:33:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 895/2585 [2:56:29<5:33:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 896/2585 [2:56:41<5:33:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 897/2585 [2:56:53<5:32:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 898/2585 [2:57:04<5:32:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 899/2585 [2:57:16<5:32:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 900/2585 [2:57:28<5:32:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5862, 'learning_rate': 0.0002, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34m35%|███▍      | 900/2585 [2:57:28<5:32:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 901/2585 [2:57:40<5:32:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 902/2585 [2:57:52<5:31:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 903/2585 [2:58:04<5:31:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 904/2585 [2:58:15<5:31:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 905/2585 [2:58:27<5:31:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 906/2585 [2:58:39<5:31:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 907/2585 [2:58:51<5:30:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 908/2585 [2:59:03<5:30:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 909/2585 [2:59:14<5:30:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 910/2585 [2:59:26<5:30:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 911/2585 [2:59:38<5:29:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 912/2585 [2:59:50<5:29:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 913/2585 [3:00:02<5:29:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 914/2585 [3:00:14<5:29:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 915/2585 [3:00:25<5:29:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 916/2585 [3:00:37<5:29:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 917/2585 [3:00:49<5:28:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 918/2585 [3:01:01<5:28:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 919/2585 [3:01:13<5:28:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 920/2585 [3:01:25<5:28:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6428, 'learning_rate': 0.0002, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 920/2585 [3:01:25<5:28:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 921/2585 [3:01:36<5:28:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 922/2585 [3:01:48<5:27:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 923/2585 [3:02:00<5:27:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 924/2585 [3:02:12<5:27:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 925/2585 [3:02:24<5:27:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 926/2585 [3:02:36<5:26:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 927/2585 [3:02:47<5:26:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 928/2585 [3:02:59<5:26:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 929/2585 [3:03:11<5:26:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 930/2585 [3:03:23<5:26:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 931/2585 [3:03:35<5:26:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 932/2585 [3:03:47<5:26:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 933/2585 [3:03:58<5:25:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 934/2585 [3:04:10<5:25:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 935/2585 [3:04:22<5:25:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 936/2585 [3:04:34<5:25:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 937/2585 [3:04:46<5:24:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 938/2585 [3:04:58<5:24:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 939/2585 [3:05:09<5:24:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 940/2585 [3:05:21<5:24:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6122, 'learning_rate': 0.0002, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m36%|███▋      | 940/2585 [3:05:21<5:24:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 941/2585 [3:05:33<5:24:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 942/2585 [3:05:45<5:23:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 943/2585 [3:05:57<5:23:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 944/2585 [3:06:09<5:23:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 945/2585 [3:06:20<5:23:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 946/2585 [3:06:32<5:23:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 947/2585 [3:06:44<5:22:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 948/2585 [3:06:56<5:22:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 949/2585 [3:07:08<5:22:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 950/2585 [3:07:19<5:22:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 951/2585 [3:07:31<5:22:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 952/2585 [3:07:43<5:21:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 953/2585 [3:07:55<5:21:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 954/2585 [3:08:07<5:21:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 955/2585 [3:08:19<5:21:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 956/2585 [3:08:30<5:21:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 957/2585 [3:08:42<5:20:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 958/2585 [3:08:54<5:20:59, 11.84s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 959/2585 [3:09:06<5:20:49, 11.84s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 960/2585 [3:09:18<5:20:43, 11.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5778, 'learning_rate': 0.0002, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 960/2585 [3:09:18<5:20:43, 11.84s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 961/2585 [3:09:30<5:20:28, 11.84s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 962/2585 [3:09:42<5:20:15, 11.84s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 963/2585 [3:09:53<5:19:57, 11.84s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 964/2585 [3:10:05<5:19:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 965/2585 [3:10:17<5:19:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 966/2585 [3:10:29<5:19:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 967/2585 [3:10:41<5:18:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 968/2585 [3:10:52<5:18:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 969/2585 [3:11:04<5:18:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 970/2585 [3:11:16<5:18:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 971/2585 [3:11:28<5:18:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 972/2585 [3:11:40<5:18:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 973/2585 [3:11:52<5:17:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 974/2585 [3:12:03<5:17:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 975/2585 [3:12:15<5:17:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 976/2585 [3:12:27<5:17:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 977/2585 [3:12:39<5:16:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 978/2585 [3:12:51<5:16:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 979/2585 [3:13:03<5:16:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 980/2585 [3:13:14<5:16:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6405, 'learning_rate': 0.0002, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 980/2585 [3:13:14<5:16:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 981/2585 [3:13:26<5:16:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 982/2585 [3:13:38<5:16:11, 11.84s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 983/2585 [3:13:50<5:16:01, 11.84s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 984/2585 [3:14:02<5:15:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 985/2585 [3:14:14<5:15:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 986/2585 [3:14:25<5:15:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 987/2585 [3:14:37<5:15:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 988/2585 [3:14:49<5:14:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 989/2585 [3:15:01<5:14:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 990/2585 [3:15:13<5:14:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 991/2585 [3:15:25<5:14:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 992/2585 [3:15:36<5:14:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 993/2585 [3:15:48<5:13:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 994/2585 [3:16:00<5:13:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 995/2585 [3:16:12<5:13:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 996/2585 [3:16:24<5:13:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 997/2585 [3:16:36<5:13:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 998/2585 [3:16:47<5:12:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 999/2585 [3:16:59<5:12:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 1000/2585 [3:17:11<5:12:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6292, 'learning_rate': 0.0002, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34m39%|███▊      | 1000/2585 [3:17:11<5:12:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 1001/2585 [3:17:23<5:12:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1002/2585 [3:17:35<5:12:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1003/2585 [3:17:47<5:11:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1004/2585 [3:17:58<5:11:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1005/2585 [3:18:10<5:11:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1006/2585 [3:18:22<5:11:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1007/2585 [3:18:34<5:11:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1008/2585 [3:18:46<5:10:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1009/2585 [3:18:58<5:10:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1010/2585 [3:19:09<5:10:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1011/2585 [3:19:21<5:10:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1012/2585 [3:19:33<5:10:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1013/2585 [3:19:45<5:10:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1014/2585 [3:19:57<5:09:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1015/2585 [3:20:09<5:09:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1016/2585 [3:20:20<5:09:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1017/2585 [3:20:32<5:09:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1018/2585 [3:20:44<5:08:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1019/2585 [3:20:56<5:08:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1020/2585 [3:21:08<5:08:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5905, 'learning_rate': 0.0002, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1020/2585 [3:21:08<5:08:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 1021/2585 [3:21:20<5:08:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1022/2585 [3:21:31<5:08:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1023/2585 [3:21:43<5:08:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1024/2585 [3:21:55<5:07:55, 11.84s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1025/2585 [3:22:07<5:07:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1026/2585 [3:22:19<5:07:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1027/2585 [3:22:31<5:07:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1028/2585 [3:22:42<5:07:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1029/2585 [3:22:54<5:06:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1030/2585 [3:23:06<5:06:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1031/2585 [3:23:18<5:06:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1032/2585 [3:23:30<5:06:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 1033/2585 [3:23:42<5:06:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1034/2585 [3:23:53<5:05:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1035/2585 [3:24:05<5:05:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1036/2585 [3:24:17<5:05:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1037/2585 [3:24:29<5:05:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1038/2585 [3:24:41<5:05:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1039/2585 [3:24:53<5:04:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1040/2585 [3:25:04<5:04:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6229, 'learning_rate': 0.0002, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m40%|████      | 1040/2585 [3:25:04<5:04:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1041/2585 [3:25:16<5:04:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1042/2585 [3:25:28<5:04:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1043/2585 [3:25:40<5:03:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1044/2585 [3:25:52<5:03:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1045/2585 [3:26:03<5:03:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 1046/2585 [3:26:15<5:03:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1047/2585 [3:26:27<5:03:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1048/2585 [3:26:39<5:03:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1049/2585 [3:26:51<5:02:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1050/2585 [3:27:03<5:02:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1051/2585 [3:27:14<5:02:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1052/2585 [3:27:26<5:02:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1053/2585 [3:27:38<5:01:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1054/2585 [3:27:50<5:01:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1055/2585 [3:28:02<5:01:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1056/2585 [3:28:14<5:01:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1057/2585 [3:28:25<5:01:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1058/2585 [3:28:37<5:01:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1059/2585 [3:28:49<5:00:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1060/2585 [3:29:01<5:00:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6036, 'learning_rate': 0.0002, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m41%|████      | 1060/2585 [3:29:01<5:00:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1061/2585 [3:29:13<5:00:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1062/2585 [3:29:25<5:00:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1063/2585 [3:29:36<5:00:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1064/2585 [3:29:48<4:59:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1065/2585 [3:30:00<4:59:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 1066/2585 [3:30:12<4:59:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 1067/2585 [3:30:24<4:59:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 1068/2585 [3:30:36<4:58:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 1069/2585 [3:30:47<4:58:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 1070/2585 [3:30:59<4:58:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 1071/2585 [3:31:11<4:58:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 1072/2585 [3:31:23<4:58:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1073/2585 [3:31:35<4:57:56, 11.82s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1074/2585 [3:31:47<4:57:45, 11.82s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1075/2585 [3:31:58<4:57:30, 11.82s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1076/2585 [3:32:10<4:57:21, 11.82s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1077/2585 [3:32:22<4:57:10, 11.82s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1078/2585 [3:32:34<4:57:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1079/2585 [3:32:46<4:56:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1080/2585 [3:32:57<4:56:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6346, 'learning_rate': 0.0002, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1080/2585 [3:32:57<4:56:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1081/2585 [3:33:09<4:56:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1082/2585 [3:33:21<4:56:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1083/2585 [3:33:33<4:56:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1084/2585 [3:33:45<4:55:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1085/2585 [3:33:57<4:55:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1086/2585 [3:34:08<4:55:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1087/2585 [3:34:20<4:55:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1088/2585 [3:34:32<4:55:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1089/2585 [3:34:44<4:54:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1090/2585 [3:34:56<4:54:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1091/2585 [3:35:08<4:54:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1092/2585 [3:35:19<4:54:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1093/2585 [3:35:31<4:54:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1094/2585 [3:35:43<4:53:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1095/2585 [3:35:55<4:53:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1096/2585 [3:36:07<4:53:42, 11.84s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1097/2585 [3:36:19<4:53:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 1098/2585 [3:36:30<4:53:20, 11.84s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1099/2585 [3:36:42<4:53:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1100/2585 [3:36:54<4:52:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5849, 'learning_rate': 0.0002, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1100/2585 [3:36:54<4:52:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1101/2585 [3:37:06<4:52:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1102/2585 [3:37:18<4:52:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1103/2585 [3:37:30<4:52:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1104/2585 [3:37:41<4:52:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1105/2585 [3:37:53<4:51:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1106/2585 [3:38:05<4:51:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1107/2585 [3:38:17<4:51:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1108/2585 [3:38:29<4:51:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1109/2585 [3:38:41<4:51:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1110/2585 [3:38:52<4:50:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1111/2585 [3:39:04<4:50:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1112/2585 [3:39:16<4:50:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1113/2585 [3:39:28<4:50:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1114/2585 [3:39:40<4:50:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1115/2585 [3:39:52<4:49:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1116/2585 [3:40:03<4:49:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1117/2585 [3:40:15<4:49:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1118/2585 [3:40:27<4:49:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1119/2585 [3:40:39<4:49:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1120/2585 [3:40:51<4:48:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6316, 'learning_rate': 0.0002, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1120/2585 [3:40:51<4:48:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1121/2585 [3:41:03<4:48:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1122/2585 [3:41:14<4:48:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1123/2585 [3:41:26<4:48:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 1124/2585 [3:41:38<4:48:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 1125/2585 [3:41:50<4:47:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 1126/2585 [3:42:02<4:47:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 1127/2585 [3:42:14<4:47:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 1128/2585 [3:42:25<4:47:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 1129/2585 [3:42:37<4:47:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 1130/2585 [3:42:49<4:46:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1131/2585 [3:43:01<4:46:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1132/2585 [3:43:13<4:46:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1133/2585 [3:43:25<4:46:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1134/2585 [3:43:36<4:46:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1135/2585 [3:43:48<4:45:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1136/2585 [3:44:00<4:45:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1137/2585 [3:44:12<4:45:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1138/2585 [3:44:24<4:45:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1139/2585 [3:44:35<4:45:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1140/2585 [3:44:47<4:44:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.578, 'learning_rate': 0.0002, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1140/2585 [3:44:47<4:44:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1141/2585 [3:44:59<4:44:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1142/2585 [3:45:11<4:44:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1143/2585 [3:45:23<4:44:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1144/2585 [3:45:35<4:44:15, 11.84s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1145/2585 [3:45:46<4:44:04, 11.84s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1146/2585 [3:45:58<4:43:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1147/2585 [3:46:10<4:43:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1148/2585 [3:46:22<4:43:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1149/2585 [3:46:34<4:43:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 1150/2585 [3:46:46<4:42:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1151/2585 [3:46:57<4:42:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1152/2585 [3:47:09<4:42:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1153/2585 [3:47:21<4:42:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1154/2585 [3:47:33<4:42:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1155/2585 [3:47:45<4:42:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1156/2585 [3:47:57<4:41:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1157/2585 [3:48:08<4:41:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1158/2585 [3:48:20<4:41:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1159/2585 [3:48:32<4:41:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1160/2585 [3:48:44<4:40:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6187, 'learning_rate': 0.0002, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1160/2585 [3:48:44<4:40:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1161/2585 [3:48:56<4:40:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1162/2585 [3:49:08<4:40:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 1163/2585 [3:49:19<4:40:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1164/2585 [3:49:31<4:40:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1165/2585 [3:49:43<4:40:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1166/2585 [3:49:55<4:39:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1167/2585 [3:50:07<4:39:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1168/2585 [3:50:19<4:39:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1169/2585 [3:50:30<4:39:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1170/2585 [3:50:42<4:39:06, 11.84s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1171/2585 [3:50:54<4:38:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1172/2585 [3:51:06<4:38:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1173/2585 [3:51:18<4:38:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1174/2585 [3:51:30<4:38:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1175/2585 [3:51:41<4:38:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 1176/2585 [3:51:53<4:37:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1177/2585 [3:52:05<4:37:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1178/2585 [3:52:17<4:37:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1179/2585 [3:52:29<4:37:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1180/2585 [3:52:41<4:37:08, 11.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6208, 'learning_rate': 0.0002, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1180/2585 [3:52:41<4:37:08, 11.84s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1181/2585 [3:52:52<4:36:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1182/2585 [3:53:04<4:36:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1183/2585 [3:53:16<4:36:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1184/2585 [3:53:28<4:36:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1185/2585 [3:53:40<4:36:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1186/2585 [3:53:52<4:35:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1187/2585 [3:54:03<4:35:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1188/2585 [3:54:15<4:35:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1189/2585 [3:54:27<4:35:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1190/2585 [3:54:39<4:35:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1191/2585 [3:54:51<4:34:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1192/2585 [3:55:03<4:35:19, 11.86s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1193/2585 [3:55:15<4:34:58, 11.85s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1194/2585 [3:55:26<4:34:41, 11.85s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 1195/2585 [3:55:38<4:34:20, 11.84s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 1196/2585 [3:55:50<4:34:04, 11.84s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 1197/2585 [3:56:02<4:33:47, 11.84s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 1198/2585 [3:56:14<4:33:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 1199/2585 [3:56:25<4:33:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 1200/2585 [3:56:37<4:33:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6062, 'learning_rate': 0.0002, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34m46%|████▋     | 1200/2585 [3:56:37<4:33:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 1201/2585 [3:56:49<4:32:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 1202/2585 [3:57:01<4:32:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1203/2585 [3:57:13<4:32:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1204/2585 [3:57:25<4:32:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1205/2585 [3:57:36<4:32:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1206/2585 [3:57:48<4:31:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1207/2585 [3:58:00<4:31:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1208/2585 [3:58:12<4:31:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1209/2585 [3:58:24<4:31:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1210/2585 [3:58:36<4:31:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1211/2585 [3:58:47<4:30:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1212/2585 [3:58:59<4:30:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1213/2585 [3:59:11<4:30:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1214/2585 [3:59:23<4:30:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1215/2585 [3:59:35<4:30:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1216/2585 [3:59:47<4:29:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1217/2585 [3:59:58<4:29:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1218/2585 [4:00:10<4:29:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1219/2585 [4:00:22<4:29:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1220/2585 [4:00:34<4:29:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5782, 'learning_rate': 0.0002, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1220/2585 [4:00:34<4:29:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1221/2585 [4:00:46<4:28:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1222/2585 [4:00:58<4:28:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1223/2585 [4:01:09<4:28:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1224/2585 [4:01:21<4:28:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1225/2585 [4:01:33<4:28:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1226/2585 [4:01:45<4:28:04, 11.84s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 1227/2585 [4:01:57<4:27:53, 11.84s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1228/2585 [4:02:09<4:27:40, 11.84s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1229/2585 [4:02:20<4:27:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1230/2585 [4:02:32<4:27:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1231/2585 [4:02:44<4:26:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1232/2585 [4:02:56<4:26:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1233/2585 [4:03:08<4:26:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1234/2585 [4:03:20<4:26:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1235/2585 [4:03:31<4:26:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1236/2585 [4:03:43<4:25:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1237/2585 [4:03:55<4:25:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1238/2585 [4:04:07<4:25:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1239/2585 [4:04:19<4:25:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1240/2585 [4:04:31<4:25:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6629, 'learning_rate': 0.0002, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1240/2585 [4:04:31<4:25:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1241/2585 [4:04:42<4:24:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1242/2585 [4:04:54<4:24:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1243/2585 [4:05:06<4:24:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1244/2585 [4:05:18<4:24:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1245/2585 [4:05:30<4:24:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1246/2585 [4:05:42<4:24:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1247/2585 [4:05:53<4:23:48, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1248/2585 [4:06:05<4:23:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1249/2585 [4:06:17<4:23:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1250/2585 [4:06:29<4:23:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1251/2585 [4:06:41<4:23:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1252/2585 [4:06:52<4:22:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 1253/2585 [4:07:04<4:22:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 1254/2585 [4:07:16<4:22:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 1255/2585 [4:07:28<4:22:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 1256/2585 [4:07:40<4:22:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 1257/2585 [4:07:52<4:21:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 1258/2585 [4:08:03<4:21:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 1259/2585 [4:08:15<4:21:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 1260/2585 [4:08:27<4:21:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5956, 'learning_rate': 0.0002, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m49%|████▊     | 1260/2585 [4:08:27<4:21:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1261/2585 [4:08:39<4:21:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1262/2585 [4:08:51<4:20:58, 11.84s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1263/2585 [4:09:03<4:20:47, 11.84s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1264/2585 [4:09:14<4:20:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1265/2585 [4:09:26<4:20:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1266/2585 [4:09:38<4:19:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1267/2585 [4:09:50<4:19:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1268/2585 [4:10:02<4:19:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1269/2585 [4:10:14<4:19:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1270/2585 [4:10:25<4:19:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1271/2585 [4:10:37<4:19:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1272/2585 [4:10:49<4:18:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1273/2585 [4:11:01<4:18:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1274/2585 [4:11:13<4:18:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1275/2585 [4:11:25<4:18:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1276/2585 [4:11:36<4:18:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1277/2585 [4:11:48<4:17:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1278/2585 [4:12:00<4:17:43, 11.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 1279/2585 [4:12:12<4:17:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1280/2585 [4:12:24<4:17:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6042, 'learning_rate': 0.0002, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1280/2585 [4:12:24<4:17:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1281/2585 [4:12:36<4:17:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1282/2585 [4:12:47<4:16:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1283/2585 [4:12:59<4:16:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1284/2585 [4:13:11<4:16:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1285/2585 [4:13:23<4:16:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1286/2585 [4:13:35<4:16:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1287/2585 [4:13:47<4:15:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1288/2585 [4:13:58<4:15:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1289/2585 [4:14:10<4:15:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1290/2585 [4:14:22<4:15:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1291/2585 [4:14:34<4:15:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 1292/2585 [4:14:46<4:14:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1293/2585 [4:14:58<4:14:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1294/2585 [4:15:09<4:14:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1295/2585 [4:15:21<4:14:13, 11.82s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1296/2585 [4:15:33<4:14:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1297/2585 [4:15:45<4:13:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1298/2585 [4:15:57<4:13:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1299/2585 [4:16:08<4:13:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1300/2585 [4:16:20<4:13:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6115, 'learning_rate': 0.0002, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34m50%|█████     | 1300/2585 [4:16:20<4:13:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1301/2585 [4:16:32<4:13:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1302/2585 [4:16:44<4:12:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1303/2585 [4:16:56<4:12:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1304/2585 [4:17:08<4:12:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 1305/2585 [4:17:19<4:12:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1306/2585 [4:17:31<4:12:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1307/2585 [4:17:43<4:11:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1308/2585 [4:17:55<4:11:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1309/2585 [4:18:07<4:11:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1310/2585 [4:18:19<4:11:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1311/2585 [4:18:30<4:11:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1312/2585 [4:18:42<4:11:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1313/2585 [4:18:54<4:10:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1314/2585 [4:19:06<4:10:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1315/2585 [4:19:18<4:10:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1316/2585 [4:19:30<4:10:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1317/2585 [4:19:41<4:10:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1318/2585 [4:19:53<4:09:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1319/2585 [4:20:05<4:09:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1320/2585 [4:20:17<4:09:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6132, 'learning_rate': 0.0002, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m51%|█████     | 1320/2585 [4:20:17<4:09:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1321/2585 [4:20:29<4:09:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1322/2585 [4:20:41<4:08:59, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1323/2585 [4:20:52<4:08:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 1324/2585 [4:21:04<4:08:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 1325/2585 [4:21:16<4:08:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 1326/2585 [4:21:28<4:08:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 1327/2585 [4:21:40<4:08:09, 11.84s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 1328/2585 [4:21:52<4:07:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 1329/2585 [4:22:03<4:07:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 1330/2585 [4:22:15<4:07:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 1331/2585 [4:22:27<4:07:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1332/2585 [4:22:39<4:07:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1333/2585 [4:22:51<4:06:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1334/2585 [4:23:03<4:06:41, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1335/2585 [4:23:14<4:06:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1336/2585 [4:23:26<4:06:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1337/2585 [4:23:38<4:06:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1338/2585 [4:23:50<4:05:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1339/2585 [4:24:02<4:05:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1340/2585 [4:24:14<4:05:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.591, 'learning_rate': 0.0002, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1340/2585 [4:24:14<4:05:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1341/2585 [4:24:25<4:05:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1342/2585 [4:24:37<4:05:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1343/2585 [4:24:49<4:04:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1344/2585 [4:25:01<4:04:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1345/2585 [4:25:13<4:04:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1346/2585 [4:25:25<4:04:21, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1347/2585 [4:25:36<4:04:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1348/2585 [4:25:48<4:03:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1349/2585 [4:26:00<4:03:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1350/2585 [4:26:12<4:03:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1351/2585 [4:26:24<4:03:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1352/2585 [4:26:36<4:03:05, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1353/2585 [4:26:47<4:02:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1354/2585 [4:26:59<4:02:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1355/2585 [4:27:11<4:02:25, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1356/2585 [4:27:23<4:02:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1357/2585 [4:27:35<4:02:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1358/2585 [4:27:46<4:01:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1359/2585 [4:27:58<4:01:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1360/2585 [4:28:10<4:01:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6132, 'learning_rate': 0.0002, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1360/2585 [4:28:10<4:01:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1361/2585 [4:28:22<4:01:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1362/2585 [4:28:34<4:01:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1363/2585 [4:28:46<4:00:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1364/2585 [4:28:57<4:00:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1365/2585 [4:29:09<4:00:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1366/2585 [4:29:21<4:00:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1367/2585 [4:29:33<4:00:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1368/2585 [4:29:45<3:59:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1369/2585 [4:29:57<3:59:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1370/2585 [4:30:08<3:59:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1371/2585 [4:30:20<3:59:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1372/2585 [4:30:32<3:59:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1373/2585 [4:30:44<3:58:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1374/2585 [4:30:56<3:58:44, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1375/2585 [4:31:08<3:58:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1376/2585 [4:31:19<3:58:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1377/2585 [4:31:31<3:58:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1378/2585 [4:31:43<3:57:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1379/2585 [4:31:55<3:57:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1380/2585 [4:32:07<3:57:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5775, 'learning_rate': 0.0002, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1380/2585 [4:32:07<3:57:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1381/2585 [4:32:19<3:57:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1382/2585 [4:32:30<3:57:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1383/2585 [4:32:42<3:56:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1384/2585 [4:32:54<3:56:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1385/2585 [4:33:06<3:56:36, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1386/2585 [4:33:18<3:56:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1387/2585 [4:33:30<3:56:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1388/2585 [4:33:41<3:56:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1389/2585 [4:33:53<3:55:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1390/2585 [4:34:05<3:55:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1391/2585 [4:34:17<3:55:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1392/2585 [4:34:29<3:55:13, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1393/2585 [4:34:41<3:55:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1394/2585 [4:34:52<3:54:49, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1395/2585 [4:35:04<3:54:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1396/2585 [4:35:16<3:54:19, 11.82s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1397/2585 [4:35:28<3:54:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1398/2585 [4:35:40<3:53:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1399/2585 [4:35:51<3:53:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1400/2585 [4:36:03<3:53:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6102, 'learning_rate': 0.0002, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1400/2585 [4:36:03<3:53:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1401/2585 [4:36:15<3:53:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1402/2585 [4:36:27<3:53:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1403/2585 [4:36:39<3:53:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1404/2585 [4:36:51<3:52:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1405/2585 [4:37:02<3:52:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1406/2585 [4:37:14<3:52:28, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1407/2585 [4:37:26<3:52:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1408/2585 [4:37:38<3:52:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1409/2585 [4:37:50<3:51:52, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1410/2585 [4:38:02<3:51:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1411/2585 [4:38:13<3:51:35, 11.84s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1412/2585 [4:38:25<3:51:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1413/2585 [4:38:37<3:51:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1414/2585 [4:38:49<3:50:58, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1415/2585 [4:39:01<3:50:47, 11.84s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1416/2585 [4:39:13<3:50:35, 11.84s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1417/2585 [4:39:24<3:50:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1418/2585 [4:39:36<3:50:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1419/2585 [4:39:48<3:49:55, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1420/2585 [4:40:00<3:49:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6061, 'learning_rate': 0.0002, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1420/2585 [4:40:00<3:49:39, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1421/2585 [4:40:12<3:49:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1422/2585 [4:40:24<3:49:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1423/2585 [4:40:35<3:49:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1424/2585 [4:40:47<3:48:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1425/2585 [4:40:59<3:48:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1426/2585 [4:41:11<3:48:33, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1427/2585 [4:41:23<3:48:18, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1428/2585 [4:41:35<3:48:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1429/2585 [4:41:46<3:47:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1430/2585 [4:41:58<3:47:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1431/2585 [4:42:10<3:47:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1432/2585 [4:42:22<3:47:23, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1433/2585 [4:42:34<3:47:10, 11.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1434/2585 [4:42:46<3:46:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1435/2585 [4:42:57<3:46:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1436/2585 [4:43:09<3:46:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1437/2585 [4:43:21<3:46:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1438/2585 [4:43:33<3:46:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1439/2585 [4:43:45<3:45:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1440/2585 [4:43:57<3:45:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5757, 'learning_rate': 0.0002, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1440/2585 [4:43:57<3:45:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1441/2585 [4:44:08<3:45:31, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1442/2585 [4:44:20<3:45:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1443/2585 [4:44:32<3:45:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1444/2585 [4:44:44<3:44:54, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1445/2585 [4:44:56<3:44:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1446/2585 [4:45:08<3:44:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1447/2585 [4:45:19<3:44:20, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1448/2585 [4:45:31<3:44:06, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1449/2585 [4:45:43<3:43:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1450/2585 [4:45:55<3:43:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1451/2585 [4:46:07<3:43:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1452/2585 [4:46:18<3:43:16, 11.82s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1453/2585 [4:46:30<3:43:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1454/2585 [4:46:42<3:42:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1455/2585 [4:46:54<3:42:47, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1456/2585 [4:47:06<3:42:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1457/2585 [4:47:18<3:42:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1458/2585 [4:47:29<3:42:15, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1459/2585 [4:47:41<3:42:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1460/2585 [4:47:53<3:41:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5922, 'learning_rate': 0.0002, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1460/2585 [4:47:53<3:41:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1461/2585 [4:48:05<3:41:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1462/2585 [4:48:17<3:41:30, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1463/2585 [4:48:29<3:41:17, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1464/2585 [4:48:40<3:41:04, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1465/2585 [4:48:52<3:40:53, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1466/2585 [4:49:04<3:40:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1467/2585 [4:49:16<3:40:29, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1468/2585 [4:49:28<3:40:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1469/2585 [4:49:40<3:40:03, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1470/2585 [4:49:51<3:39:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1471/2585 [4:50:03<3:39:40, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1472/2585 [4:50:15<3:39:27, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1473/2585 [4:50:27<3:39:16, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1474/2585 [4:50:39<3:39:01, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1475/2585 [4:50:51<3:38:51, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1476/2585 [4:51:02<3:38:37, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1477/2585 [4:51:14<3:38:26, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1478/2585 [4:51:26<3:38:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1479/2585 [4:51:38<3:38:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1480/2585 [4:51:50<3:37:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5648, 'learning_rate': 0.0002, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1480/2585 [4:51:50<3:37:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1481/2585 [4:52:02<3:37:46, 11.84s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1482/2585 [4:52:13<3:37:34, 11.84s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1483/2585 [4:52:25<3:37:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1484/2585 [4:52:37<3:37:07, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1485/2585 [4:52:49<3:36:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1486/2585 [4:53:01<3:36:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1487/2585 [4:53:13<3:36:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1488/2585 [4:53:24<3:36:19, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1489/2585 [4:53:36<3:36:08, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1490/2585 [4:53:48<3:35:57, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1491/2585 [4:54:00<3:35:46, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1492/2585 [4:54:12<3:35:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1493/2585 [4:54:24<3:35:23, 11.84s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1494/2585 [4:54:35<3:35:09, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1495/2585 [4:54:47<3:34:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1496/2585 [4:54:59<3:34:42, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 1517/2585 [4:59:08<3:30:35, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 1518/2585 [4:59:19<3:30:24, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1519/2585 [4:59:31<3:30:11, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1520/2585 [4:59:43<3:30:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5809, 'learning_rate': 0.0002, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1520/2585 [4:59:43<3:30:00, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1521/2585 [4:59:55<3:29:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1522/2585 [5:00:07<3:29:38, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1523/2585 [5:00:19<3:29:29, 11.84s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1524/2585 [5:00:30<3:29:14, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1525/2585 [5:00:42<3:28:56, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1526/2585 [5:00:54<3:28:45, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1527/2585 [5:01:06<3:28:32, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1528/2585 [5:01:18<3:28:22, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1529/2585 [5:01:30<3:28:12, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1530/2585 [5:01:41<3:28:02, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1531/2585 [5:01:53<3:27:50, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1532/2585 [5:02:05<3:27:34, 11.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1533/2585 [5:02:17<3:27:20, 11.83s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f5a324-b114-4ac4-8440-bf77449fa326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'huggingface_estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhuggingface_estimator\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS3DataSource\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS3Uri\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://s3.console.aws.amazon.com/s3/buckets/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-394697995665/huggingface-qlora-HuggingFaceH4-zephyr--2023-12-29-12-32-49-648/output/model/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'huggingface_estimator' is not defined"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"].replace(\"s3://\", \"https://s3.console.aws.amazon.com/s3/buckets/\")=='https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-394697995665/huggingface-qlora-HuggingFaceH4-zephyr--2023-12-29-12-32-49-648/output/model/'\n",
    "s3://sagemaker-us-east-1-394697995665/huggingface-qlora-HuggingFaceH4-zephyr--2023-12-29-12-32-49-648/output/model/\n",
    "s3://sagemaker-us-east-1-394697995665/huggingface-qlora-HuggingFaceH4-zephyr--2024-01-05-09-12-58-591/output/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c05b7-a074-4b08-947e-0c4401726c28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb15c3ac-53ee-4221-b113-719010bce49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c98257-0a0f-4ce6-afc8-f3313301fb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time add the s3 path here\n",
    "model_s3_path = 's3://sagemaker-us-east-1-394697995665/huggingface-qlora-HuggingFaceH4-zephyr--2024-01-05-09-12-58-591/output/model/'\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(4096), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(16000), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cda45ab-834e-4809-92ef-2aad04e0345b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cacf7b1-4bbc-48d7-8f22-ff0197301174",
   "metadata": {},
   "outputs": [],
   "source": [
    "<|system|>\n",
    "You are a pirate chatbot who always responds with Arr!</s>\n",
    "<|user|>\n",
    "There's a llama on my lawn, how can I get rid of him?</s>\n",
    "<|assistant|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1dbd76b-00f9-4506-bd81-db809bf8b9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "\n",
    "# hyperparameters for llm\n",
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.8,\n",
    "    \"max_new_tokens\": 4000,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"\\nUser:\", \"<|endoftext|>\", \" User:\", \"###\"],\n",
    "}\n",
    "\n",
    "system_prompt = \"You are an helpful Assistant, called Falcon. Knowing everyting about AWS.\"\n",
    "\n",
    "\n",
    "# Helper for reading lines from a stream\n",
    "class LineIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "            if \"PayloadPart\" not in chunk:\n",
    "                print(\"Unknown event type:\" + chunk)\n",
    "                continue\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])\n",
    "\n",
    "\n",
    "# helper method to format prompt\n",
    "def format_prompt(message, history, system_prompt):\n",
    "    prompt = \"\"\n",
    "    if system_prompt:\n",
    "        prompt += f\"System: {system_prompt}\\n\"\n",
    "    for user_prompt, bot_response in history:\n",
    "        prompt += f\"User: {user_prompt}\\n\"\n",
    "        prompt += f\"Falcon: {bot_response}\\n\"  # Response already contains \"Falcon: \"\n",
    "    prompt += f\"\"\"User: {message}\n",
    "Falcon:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def create_gradio_app(\n",
    "    endpoint_name,\n",
    "    session=boto3,\n",
    "    parameters=parameters,\n",
    "    system_prompt=system_prompt,\n",
    "    format_prompt=format_prompt,\n",
    "    concurrency_count=10,\n",
    "    share=True,\n",
    "):\n",
    "    smr = session.client(\"sagemaker-runtime\")\n",
    "\n",
    "    def generate(\n",
    "        prompt,\n",
    "        history,\n",
    "    ):\n",
    "        formatted_prompt = format_prompt(prompt, history, system_prompt)\n",
    "\n",
    "        request = {\"inputs\": formatted_prompt, \"parameters\": parameters, \"stream\": True}\n",
    "        resp = smr.invoke_endpoint_with_response_stream(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(request),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "\n",
    "        output = \"\"\n",
    "        for c in LineIterator(resp[\"Body\"]):\n",
    "            c = c.decode(\"utf-8\")\n",
    "            if c.startswith(\"data:\"):\n",
    "                chunk = json.loads(c.lstrip(\"data:\").rstrip(\"/n\"))\n",
    "                if chunk[\"token\"][\"special\"]:\n",
    "                    continue\n",
    "                if chunk[\"token\"][\"text\"] in request[\"parameters\"][\"stop\"]:\n",
    "                    break\n",
    "                output += chunk[\"token\"][\"text\"]\n",
    "                for stop_str in request[\"parameters\"][\"stop\"]:\n",
    "                    if output.endswith(stop_str):\n",
    "                        output = output[: -len(stop_str)]\n",
    "                        output = output.rstrip()\n",
    "                        yield output\n",
    "\n",
    "                yield output\n",
    "        return output\n",
    "\n",
    "    demo = gr.ChatInterface(generate, title=\"Chat with Amazon SageMaker\", chatbot=gr.Chatbot(layout=\"panel\"))\n",
    "\n",
    "    demo.queue(concurrency_count=concurrency_count).launch(share=share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db5d2e76-aa2e-4064-ae5e-04db77492f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "---------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"My name is Julien and I like to make things.\\n\\nI'm a French-Canadian living in Montreal, Canada.\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'openchat/openchat-3.5-1210',\n",
    "\t'SM_NUM_GPUS': json.dumps(1),\n",
    "    'MAX_INPUT_LENGTH': json.dumps(4096),\n",
    "    'MAX_TOTAL_TOKENS': json.dumps(14096)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.2xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "  )\n",
    "  \n",
    "# send request\n",
    "predictor.predict({\n",
    "\t\"inputs\": \"My name is Julien and I like to\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e350bc-0115-4e53-9ac9-4cca4c13d033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.1.0 Python 3.10 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.1.0-cpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
